
%% bare_jrnl.tex
%% V1.4a
%% 2014/09/17
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8a or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_conf_compsoc.tex,
%%                    bare_jrnl_compsoc.tex, bare_jrnl_transmag.tex
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices and paper sizes can       ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[journal]{IEEEtran}
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/tex-archive/info/epslatex/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
\ifCLASSOPTIONcompsoc
  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
\else
  \usepackage[caption=false,font=footnotesize]{subfig}
\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/




% *** FLOAT PACKAGES ***
%
% \usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/


% \usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Do not use the stfloats baselinefloat ability as IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
\usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/dblfloatfix/




\ifCLASSOPTIONcaptionsoff
  \usepackage[nomarkers]{endfloat}
 \let\MYoriglatexcaption\caption
 \renewcommand{\caption}[2][\relax]{\MYoriglatexcaption[#2]{#2}}
\fi
% endfloat.sty was written by James Darrell McCauley, Jeff Goldberg and 
% Axel Sommerfeldt. This package may be useful when used in conjunction with 
% IEEEtran.cls'  captionsoff option. Some IEEE journals/societies require that
% submissions have lists of figures/tables at the end of the paper and that
% figures/tables without any captions are placed on a page by themselves at
% the end of the document. If needed, the draftcls IEEEtran class option or
% \CLASSINPUTbaselinestretch interface can be used to increase the line
% spacing as well. Be sure and use the nomarkers option of endfloat to
% prevent endfloat from "marking" where the figures would have been placed
% in the text. The two hack lines of code above are a slight modification of
% that suggested by in the endfloat docs (section 8.4.1) to ensure that
% the full captions always appear in the list of figures/tables - even if
% the user used the short optional argument of \caption[]{}.
% IEEE papers do not typically make use of \caption[]'s optional argument,
% so this should not be an issue. A similar trick can be used to disable
% captions of packages such as subfig.sty that lack options to turn off
% the subcaptions:
% For subfig.sty:
% \let\MYorigsubfloat\subfloat
% \renewcommand{\subfloat}[2][\relax]{\MYorigsubfloat[]{#2}}
% However, the above trick will not work if both optional arguments of
% the \subfloat command are used. Furthermore, there needs to be a
% description of each subfigure *somewhere* and endfloat does not add
% subfigure captions to its list of figures. Thus, the best approach is to
% avoid the use of subfigure captions (many IEEE journals avoid them anyway)
% and instead reference/explain all the subfigures within the main caption.
% The latest version of endfloat.sty and its documentation can obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/endfloat/
%
% The IEEEtran \ifCLASSOPTIONcaptionsoff conditional can also be used
% later in the document, say, to conditionally put the References on a 
% page by themselves.




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/url/
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}

% My packages
\usepackage{comment}
\usepackage{algorithm}
\usepackage{lipsum}
\usepackage{rumathmacros}

% My mods:
\newcommand{\papertitle}{Constructing the Pareto Front using Limited Information: A Case of the Opposition based Solution Generation Scheme}
\graphicspath{%
	{./results/zdt1/}%
	{./results/zdt2/}%
	{./results/zdt3/}%
	{./results/zdt4/}%
	{./results/zdt6/}%
	{./results/dtlz1/}%
	{./results/dtlz2/}%
	{./results/dtlz3/}%
	{./results/dtlz4/}%
	{./results/dtlz5/}%
	{./results/dtlz6/}%
	{./figs/}%
}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
% \title{Bare Demo of IEEEtran.cls for Journals}
\title{\papertitle}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

% author{AKM~Khaled~Ahsan~Talukder,\\\textbf{Experiment Report for CSE 890 Course}}
\author{Author~1,~\IEEEmembership{Member,~IEEE,}
         Author~2,~\IEEEmembership{Member,~OSA,}
         and~Author~3,~\IEEEmembership{Member,~IEEE}% <-this % stops a space
% \thanks{M. Shell is with the Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, 30332 USA e-mail: (see http://www.michaelshell.org/contact.html).}% <-this % stops a space
\thanks{Author-1 and Authtor-2 are with Anonymous University.}% <-this % stops a space
% \thanks{Manuscript received April 19, 2005; revised September 17, 2014.}%
}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.



% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~13, No.~9, September~2014}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.




% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2014 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.



% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
In this paper we investigate a curious example of opposition based solution generation applied to an evolutionary multi-objective optimization (EMO) algorithm, namely on NSGA-II. In this paper we will see how the concept of Opposition Based Learning (OBL) can be reformulated to suite the Multi-objective Optimization (MOP) settings. We have devised a simple and an intuitive approach for OBL so that it can be applied to any elitist EMO algorithm. We have also conducted an in-depth analysis of the efficacy of our approach to a wide range of benchmark MOP test functions. We have also proposed a definitive guideline to how to find the extreme solutions on the true Pareto-front. Our proposed model utilizes a deterministic solution generation scheme that is guided by the opposite traits imposed on the current population individuals. Our study have also addressed some boundary issues -- such as the quantitative applicability of the opposite solutions generated by our approach.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
% \begin{IEEEkeywords}
% IEEEtran, journal, \LaTeX, paper, template.
% \end{IEEEkeywords}






% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
% \IEEEPARstart{T}{his} demo file is intended to serve as a ``starter file''
% for IEEE journal papers produced under \LaTeX\ using
% IEEEtran.cls version 1.8a and later.

\IEEEPARstart{I}{n} the recent years, the idea of Opposition Based Learning (OBL) has been enjoying a noticeable attention among the AI and OR practitioners. The idea of OBL is to accelerate the learning rate (or convergence rate) by imposing an opposite estimate of the current solution, and deliberately introducing them to influence the search trajectory. This idea was first introduced in \cite{obl-main} and has been demonstrated its effectiveness in different scenarios -- from Reinforcement Learning (RL) \cite{obl-rl}, Differential Evolution (DE) \cite{ode-main} to robotics \cite{ode-robot}. 

In all of the cases, the OBL comes into play specially during the initialization phase of the learning algorithm (or optimization algorithm), the argument behind this strategy is that a completely arbitrary (i.e. blind) initialization is no better than an informed boot-strap. Since a random sampling or selection of solutions from a given population has the possibility of visiting or even revisiting unpromising regions of the search space. In \cite{ode-main}, it has also been demonstrated that the chance of such revisits are lower in the case of opposite than it is for purely random initialization. There is also a formal proof that shows that, in general, the opposite estimations are more likely to be closer to the optimal solution than the completely arbitrary ones \cite{theory-1}. A more details of a formal probabilistic analysis of opposition based learning can also be found in \cite{theory-2}.

Moreover, especially for the case of optimization algorithms, it has been demonstrated that keeping a small ratio of solutions with the opposite estimate helps to converge better \cite{opbil} -- and most of the recent studies are inspired by this approach. For example, in \cite{omoead} similar strategy has been used in the case of MOEA/D \cite{moead-main}. We have also seen identical examples in \cite{omode}. Another relevant study can be found in \cite{opso}, where the opposition based initialization has been tested with the Particle Swarm Optimization (PSO) scenario to induce a better convergence. Given all of these studies, still we could not find a good example of this idea applied to the Evolutionary Multi-objective Optimization (EMO) cases -- more importantly -- in a more meaningful and precise way. In this study we will try to fill this gap in an interesting and simpler way. 

In our approach, we will address this idea of \textit{opposition} in a different perspective, we will classify the (not to be confused with the term ``classification'' in machine learning domain) solutions with respect to some \textit{desired traits} that we will like to have. Then we will use this information to deterministically generate new solutions in a most viable locations in the search space -- and this operation will be dictated by our special notion of opposition. In fact, our approach is somewhat similar in spirit to the previous studies done in \cite{sts-1}, \cite{sts-2} and \cite{directional-mutation}. Except the fact that our approach is extremely simple and does not assume any special property on the underlying search space, moreover, our approach does not build a computationally expensive models as done in \cite{search-history}\cite{segment-search}.

This paper is organized as follows -- first we will discuss why this idea of OBL needs to be reinterpreted for the Multi-objective Optimization (MOP) setting. Next we discuss one interesting limitation that most EMO algorithms suffer from -- the \textit{search trajectory bias}, and also give some argument on why such hindrance becomes inevitable. Then we will discuss how the idea of OBL can come into rescue. In our model, we generate the opposite points in a strictly deterministic way, by carrying out the arbitration of \textit{opposition} in a different (and a more MOP relevant manner). To do this, we utilize the extreme solutions on the true Pareto-front (PF), and the next section discusses how to find them efficiently. After that we will describe our main algorithm in details. Then we will show our experiments with different benchmark MOP problem sets. We will also see some boundary issues with our models -- like how the opposite points get utilized during the run, and some what-if analysis by integrating our models into the canonical EMO algorithm, namely in NSGA-II \cite{nsga2-main}. We will also see how this approach becomes more useful if the underlying search space becomes more complex or computationally more expensive to explore. Then we conclude our study by discussing some future guidelines to extend our idea.

% You must have at least 2 lines in the paragraph with the drop letter
% (should never be an issue)
% I wish you the best of success.

% \hfill mds
 
% \hfill September 17, 2014

\section{An Alternative Interpretation of Opposition}
\label{sec:alternative-interpretation}
As we have already seen in the previous section, in most of the studies, the idea of \textit{opposition} is employed as an incorporation of new solutions with a certain kind of \textit{opposite traits} into the existing population. Such traits could be interpreted in terms of different problem domain perspectives. For example, the \textit{opposite} solutions could be -- i) the ones with complete opposite representation from the current best individual, ii) the ones with the opposite estimates from the other spectrum of the variable bounds (i.e. in the case of real valued optimization). However, the injection of the opposite solutions could cause a re-route from the continuing search trajectory and thus could be a misleading operation -- in a sense that the opposite solutions might be useful given that the search space follows a desired pattern. 

For example, if the task is to solve the N-queen problem, then the opposite representation of the current best can result into another valid global optima. One can easily verify this by computing the reverse assignment of queens from a existing optimal solution; and it will eventually take us to another global optima. This observation also assumes that the search space is multi-modal, following from the fact that the reverse representation of the current best solution needs to be an optimum for another peak of the search space. Therefore, most of the standard opposition based algorithms inject the opposite solutions during the optimization start-up; or maintain a constant (generally low) ratio of opposite points throughout the run. Therefore, the standard opposite injection scheme could only be effective given the two assumptions on the underlying search space are valid -- multi-modality and the solution symmetry. For this reason, what we think -- such approach is quite unwieldy to directly incorporate into a large scale numerical optimization problems, e.g. multi-objective optimization problems (MOPs).

Moreover, we have also seen some examples of opposition based algorithm for Q-learning/TD-learning like scenarios \cite{obl-rl}. Similar argument can be made, as the reinforcement-learning algorithms are inherently greedy (as they rely on the Bellman's optimality principle). And the opposite actions during the learning phase introduces a noise; so that the search can branch out to alternative choices. In that sense, we can say that the injection of opposite solutions can be considered as a different form of \textit{variation operator} in population based stochastic search. 

However, in the case of complex problem solving, the existing opposition based solution generation schemes may not be always effective. As we think, they are ``blind'' -- the opposite solutions are generated from the current best in an arbitrary manner. The existing approaches do not take account other important requirements that a good solution needs to be abide by. For example, if we arbitrarily create an completely opposite solution from the current best without considering any constraint, we could end up with a solution with a worst fitness value or a solution that violates constraints. Therefore, we think this idea of opposition needs to be revised, so that we can model the opposite traits as the choice between the \textit{good} and \textit{bad} solutions.

Moreover, in the numerical optimization scenarios, we hardly have rooms to make any assumption about the multi-modality of the search space and/or the symmetry of the solution representation (i.e. unlike such assumptions could be made about the N-queen problem). Therefore, in this paper, we have revised the notion of opposition in terms of the preference criteria imposed on a solution. For example, most evolutionary multi-objective optimization (EMO) algorithms aim to maximize two principal properties -- i) the convergence and ii) the diversity, since the quality of a MOP solution depends on these two factors. Therefore, let us re-consider the opposite point generation/injection in a different perspective --
\begin{itemize}
	\item Opposite Convergence: A solution \textit{far} from the true Pareto-front is \textit{opposite} to any solution that is \textit{closer} to the true Pareto-front.
	\item Opposite Diversity: An \textit{isolated} solution on the true Pareto-front is \textit{opposite} to a \textit{crowded} solution. 
\end{itemize}

By taking the above two principles into account, we will deterministically generate opposite solutions during the search. Obviously, the deterministic point generation scheme will only consider an opposite trait that is \textit{good}. In the next section we will see, how the existing EMO algorithms shows the limitations maintaining this two opposite traits during the search (i.e. solution generation) process.  

\section{Limitations with the Canonical EMO Algorithms: The Search Trajectory Bias}
\label{sec:limitation-canonical}
Most of the standard EMO algorithms (e.g. NSGA-II, SPEA-II \cite{spea2-main} etc.), are elitist by design. They are also ``opportunistic'' in a sense that the population always try to converge to a particular portion of the Pareto-front (PF) which seems to be easier to solve at that moment. They also shows a preference over a certain objective function which needs less exploration than the other. We can see such bias in the search when we try to solve the ZDT4 problem using NSGA-II. In such case, the first objective is easier to optimize than the second one, the readers can verify this fact from the figure \ref{fig:zdt4-unbalanced-snapshot}. Therefore, the search trajectory deliberately accumulates more points over the first objective to optimize one particular portion of the Pareto-front. Moreover, while putting more solutions to the vicinity of one particular objective axis, the search trajectory looses the uniformity by forming a crowded streak of points along that axis; on the other hand we can see that there is almost no solution on the other spectrum of the objective space. This kind of non-symmetric search behaviour is, we think, causes a hindrance to the optimization algorithm. Therefore, it would be helpful if we could selectively inject points during the search where the solution distribution is more sparse. In addition, we also think that this biased nature of the search trajectory could degrade with the addition of more objective functions. Moreover, this could also lead to a stagnation on the local optima, given that the search space has a lot many of them.

Given this specific scenario, now the main problem is to devise a way to deterministically generate points where the distribution of the solution is sparse. Here we assume that the lesser the number of solutions in a vicinity of objective \(f_i\), the harder it is to solve. This would be easy if we know the exact mapping of the design variable to objective values -- however such mapping is always unavailable and above all it is very expensive to infer. Another way could be to mutate the points where the solution is more sparse, but we think as the original algorithm already goes through such step, it is not going to be very effective\footnote{However, in the section \ref{subsec:nsga2re} we will demonstrate this fact that just mutating the sparse solutions does not help much.}. 

In this paper we are going to demonstrate a very effective approach to address this issue, we will show how we can maintain a balanced distribution of solutions that is parallel to the true PF. The proposed approach is also extremely effective in fast converging to the true PF as well.   
% Figure
\begin{figure}[tp]
\centering
\includegraphics[width=0.5\textwidth]{zdt4-bias}
\caption{The effect of the \textit{search trajectory bias} could be seen when we try to solve ZDT4 problem with NSGA-II. Here we can see a long streak of crowded solution near the objective \(f_2\), where the distribution of solutions near the objective \(f_1\) is extremely sparse.}
\label{fig:zdt4-unbalanced-snapshot}
\end{figure}

\section{The Deterministic Opposite Point Generation Scheme}
\label{sec:generation-scheme}
As we have discussed in the section \ref{sec:alternative-interpretation}, we will utilize the so-called notion of \textit{opposition} to deterministically generate points into strategically useful places on the search space. In principle, we do not assume any exact mapping over the design variables to objective values, and we apply a linear translation to achieve our goal effectively\footnote{As a matter of fact, we will also see in the later sections that such opposite points are generally \(\sim 30\%\) useful in most cases and they are more effective during the initial generations -- which is also a very interesting finding.}. In essence, instead of considering \textit{sparsity} and \textit{crowd} as two opposite traits, our method can impose any criteria like \textit{being `x'} and \textit{being `y'} as two opposites. Being said that, linear translation is a simplest way to deterministically generate \textit{`x' like} solutions from \textit{`y' like} ones. 

So, our basic approach is to infer the true PF before starting the actual optimization run. To do this, we depend on barely \(k\) number (\(k = \text{number of objectives}\)) of extreme (or near extreme) points on the true PF since we can safely assume that the population will eventually reach to the vicinity of those extreme points in the end. Moreover, the extreme points will be used as a pivot to arbitrate between the opposite traits over the existing solutions. Also note that we are not going to deterministically define which portion of the search space is less easy (or hard) and so forth -- we will try to devise a technique that will automatically address and solve such issues on the fly.

Another reason to fixate over the \(k\) extreme points is that we also wanted to keep the algorithm simple so that it can only utilize the ``minimal information'' of the true PF. We also think it's valid to assume that any PF could be bounded by at least \(k\)-extreme points for any \(k\)-objective problem. Although, if we could supply other intermediary points on the true PF, we will be able to see a better performance gain with the existing model, however supply of \(1\) extra true PF solution comes with an added cost of extra function evaluations. As the extreme (or near extreme) points are the pivot to define the notion of \textit{opposite} in our case, we will start the next section by discussing how to find them efficiently.

\subsection{Finding the Extreme Points}
\label{sec:find-extreme-points}
Extreme points on the Pareto-front could be found using global search as well \cite{nadir-estimation}, however our goal was to save the extra computational cost as much as possible\footnote{The readers might be aware that efficiently finding the extreme points on the true Pareto-front is itself a separate research problem.}. Therefore, we resort to the classical single-objective optimization methods to solve this problem. Our choice of such algorithms were limited to, namely, the Interior Point (IP) method and the Mesh Adaptive Direct Search (MADS)\footnote{We have used the \texttt{fmincon()} and the \texttt{patternsearch()} routine in MATLAB (v. R2014a) for IP method and MADS respectively.}. As we also did not want to spend the valuable function evaluations for this purpose, we have conducted this extreme solution search as a fixed budget operation. Depending on the difficulty of the problems, appropriate routine parameters were empirically found out and they are problem dependent. These settings can be summarized as follows: 
%
\begin{algorithm}[pb]
\caption{Find Extreme Points}
\label{algo:find-extreme-points}
\begin{algorithmic}[1]
	\STATE $k \leftarrow$ no. of objectives
	\STATE $N_p \leftarrow$ population size
	\STATE $N_{\text{gen}} \leftarrow$ maximum generation
	\STATE $T \leftarrow \frac{1}{k}(\frac{1}{4}N_p N_{\text{gen}})$
	\STATE $E^\ast \leftarrow \emptyset$, an empty solution set
	\FOR{$i$ from $1$ \TO $k$}
		\STATE $f_i \leftarrow$ $i$-th objective function
		\STATE $x_i \leftarrow $ random initial vector
		\REPEAT
			\STATE $x_i \leftarrow$ solve $f_i$ with IP method (or MADS) 
		\UNTIL{$\frac{T}{2}$ function evaluation reached}
		\STATE $f_{\text{aasf}} \leftarrow $ construct AASF function from $f_i$
		\REPEAT
			\STATE $x_i \leftarrow$ solve $f_{\text{aasf}}$ with  IP method (or MADS)
		\UNTIL{$\frac{T}{2}$ function evaluation reached}
		\STATE $E^\ast \leftarrow \{E^\ast \cup x_i\}$
	\ENDFOR
	\RETURN $E^\ast$
\end{algorithmic}
\end{algorithm}
%
\begin{itemize}
	\item If the problem has no local optima then we use IP method (i.e. \texttt{fmincon()}), it has been found to be comparatively less expensive even if the variable size is large.
	\item If the problem has local optima, MADS (i.e. \texttt{patternsearch()}) is faster for finding more accurate extreme points. However, if the number of objective is $k > 2$, then these settings are found to be more useful:
		\begin{itemize}
			\item \texttt{InitialMeshSize:} \(1/\text{population size}\)
			\item \texttt{Search Method:} \texttt{@MADSPositiveBasis2N} to start searching with $2N$ random directions, where $N =$ number of variables.
			\item and keeping \texttt{CompletePoll:} to \texttt{on} and\\ \texttt{CompleteSearch:} to \texttt{on}
		\end{itemize}
\end{itemize}
%
The readers should be aware that the algorithm parameter that we have found is not a general setting, they have been set according to the problem structure, so they are subjected to empirical investigations and the problem domain-knowledge. 

The actual extreme point computation algorithm was conducted in two steps -- given a particular objective function \(f_i\), first we try to solve it directly using either IPM or MADS (depending on the problem type); then after some \(\frac{T}{2}\) iterations, we construct the so-called Augmented Achievement Scalarizing Function (AASF) function from \(f_i\) and solve it again for \(\frac{T}{2}\) iterations. To limit the function evaluations, we kept \(T\) to a constant value (as a budget). For all problems, we have fixed this maximum iteration count to the \(\frac{1}{4}\)-th of the total generation specified. More precisely, $T = \frac{1}{k}(\frac{1}{4}N_p N_{\text{gen}})$, where $k = \text{no. of objectives}$, $N_p = \text{population size}$ and $N_{\text{gen}} = \text{maximum generation}$. A basic listing for this routine is presented in Algorithm \ref{algo:find-extreme-points}. The set of the extreme points \(E^\ast\) generated from this algorithm may not contain all the unique solution, and also they might not be the true extreme always, they can be weakly dominated solutions by the true PF extremes. However, our approach can utilize them efficiently to converge to the true PF extremes.

% Figure
\begin{figure}[tp!]
\centering
\includegraphics[width=0.5\textwidth]{zdt4-gap}
\caption{The effect of the \textit{gap} in the trade-off, could be seen when we try to solve ZDT4 problem with NSGA-II.}
\label{fig:zdt4-gap-snapshot}
\end{figure}
%
\subsection{The Opposite Solution Generation Algorithm}
\label{sec:generate-pivot-points}
Once the extreme points are discovered, now we utilize them to generate the so-called \textit{opposite} points during the main evolutionary runs. On each generation, we randomly select 25\% individuals from the current population and deterministically change them to generate opposite solutions -- in such a way that we can address the strategically preferable places. And to conduct this variation, we will utilize the points in the set \(E^\ast\) as pivot points. We call these points as ``pivot'' since we will selectively try to generate points around these pivots. However, before doing this, we will \textit{refine} our pivot points \(E^\ast\) in a certain way. 

The \textit{refinement} starts by finding the current population extreme points \(E_c\) and merging them with the set \(E^\ast\) such that \(E = \{E_c \cup E^\ast\}\). Next we apply the non-dominated sort on \(E\) to find the Pareto-front within this set. We apply this sorting because we are not still sure if \(E^\ast\) contains true PF extremes. This sorting will keep the true extreme points if ones are found in the later generations. After this step, we select the points from \(E\) that are on the best front and with \(\infty\) crowding distances\footnote{By ``crowding distance'', we mean the inter-solution distances computed in NSGA-II.}. Lets denote these selected points as \(E'\). Now at this point, two situations are possible:
%
\begin{itemize}
	\item The set \(E'\) contains only the solutions \(E^\ast\) while we are in the initial generations, or
	\item The set \(E'\) contains the solutions \(E_c\) while we are in the later phase of the generations, where \(E_c\) are the true PF extreme. 
\end{itemize}

\begin{algorithm}[tp]
\caption{Generate Pivot Points}
\label{algo:generate-pivot-points}
\begin{algorithmic}[1]
	\REQUIRE true PF extreme points $E^{\ast}$ from Algorithm \ref{algo:find-extreme-points}
	\STATE $E_c \leftarrow$ the extreme points from the current PF
	\STATE $E \leftarrow \{E^\ast \cup E_c\}$
	\STATE rank points in $E$, $E \rightarrow \{\mathcal{F}_1, \mathcal{F}_2, \ldots, \mathcal{F}_n\}$
	\STATE take the best front in $E'$, $E' \leftarrow \mathcal{F}_1$
	\FOR{all points $p_i$ in $E - E'$}
		\IF{$p_i$ weakly dominates any $p_j \in E'$}
			\STATE replace $p_j$ by $p_i$
		\ENDIF
	\ENDFOR
	\STATE update $E^\ast$, $E^\ast \leftarrow E'$
	\STATE $G \leftarrow$ find $k$ intermediary gap points from the current PF
	\STATE $E' \leftarrow \{E' \cup G\}$
	\RETURN $E'$
\end{algorithmic}
\end{algorithm}

However, during the intermediate generations, it can also happen that we may include some solutions into \(E\) that weakly dominate a subset of points already in \(E\), this inclusion will reduce the expected spread of the pivot points -- that may diminish the effect of maintaining the diversity. For example, if the actual true PF is a broken Pareto-front, and if \(E\) contains the extreme points from one broken edge, then we need to expand the current edges so that the refinement procedure can include points from the further extreme ends. Therefore, if there exist a point in \(E - E'\) that is on the best front and also weakly dominated by any point in \(E'\), then we replace the weakly dominating point from \(E'\) with the one from the set \(E - E'\). The readers might have already noticed that \(|E'| \le |E|\).

Now, at this point, we can ensure that the set \(E'\) contains either true PF extremes or points near them. Now if we can generate new points near \(E'\), they will induce both better convergence and diversity. In section \ref{sec:limitation-canonical}, we have discussed a scenario where we can see how the bias in the search trajectory is introduced. However, the difference in the relative difficulty of the objective functions may not be the only reason for a bias. The imbalance in the solution distribution could happen for other reasons as well. For example, a disconnected Pareto-front, a local optimal front or a specific portion of the Pareto-front being more difficult to solve than the rest. In such cases, we can see a \textit{gap} forming over the Pareto-front during the search, we can see such a convergence pattern in many problems. As an example, we can see similar effect in solving ZDT4 problem as illustrated in Figure \ref{fig:zdt4-gap-snapshot}. To address these \textit{gaps}, we also find the solutions with \(k\)-highest (\(k = \) no. of objectives) crowding distance from the best front that are not \(\infty\), and call them as set \(G\). Clearly, the \(G\) solutions are those that reside on the edge of the broken front. Now we add the \(G\) to the set \(E'\), thus we make \(E'\) as the final ``pivot'' solutions to generate the opposite points. This should be also noted that \(|E'| > k\). This procedure is presented in Algorithm \ref{algo:generate-pivot-points}.

% Figure
\begin{figure}[tp!]
\centering
\includegraphics[width=0.5\textwidth]{point-generation}
\caption{The illustration of lines 9--12 in Algorithm \ref{algo:onsga2}. The point \(\mathbf{x_c}\) is the child and \(\mathbf{x_p}\) is the parent. The point \(\mathbf{v}\) are the pivot points. The operation will choose one of the directions denoted by \(L_1\), \(L_2\) or \(L_3\). Points with overshoot (invalid points) are corrected using the variable bounds.}
\label{fig:opposite-creation}
\end{figure}
%
\subsection{Integrating into an Elitist EMO Algorithm: NSGA-II}
\label{sec:onsga2r}
As we have mentioned at the beginning that we randomly select 25\% of the current population for opposite point generation. We go through each of them and every time we randomly pick \(k\) number of random points from \(E'\) and pick the pivot point that is the furthest from it, and find the opposite vector using a linear translation. A straight-forward way -- given a pivot vector \(\mathbf{v}\) and a parent vector \(\mathbf{x_p}\), we generate an opposite child \(\mathbf{x_c}\) as \(\mathbf{x_c} = \mathbf{x_p} + \mathbf{U}[(\frac{3d}{4}, \frac{5d}{4})] \circ (\frac{1}{d}(\mathbf{x_p} - \mathbf{v}))\). Here, \(d = ||\mathbf{v} - \mathbf{x_p}||\) and \(\mathbf{U}[(d,u)]\) is a uniform random vector where each element is within the range \([d,u]\). The overall procedure is presented in Algorithm \ref{algo:onsga2} in line 9--12 and illustrated in the Figure \ref{fig:opposite-creation}. The lines 9--12 in Algorithm \ref{algo:onsga2} can be recapped as follows: \(\mathbf{v}\) is on the true PF extreme and \(\mathbf{x_i}\) is \textit{far} from \(\mathbf{v}\), therefore, move \(\mathbf{x_i}\) closer to \(\mathbf{v}\) -- \textit{opposite} of \textit{far} is \textit{close}. Similar interpretation can be made when the vector \(\mathbf{v}\) is an intermediary \textit{gap}. 

When we apply this algorithm to NSGA-II, we follow the obvious way, the generated opposite population will be inserted into the child population \(Q_t\), the Algorithm \ref{algo:onsga2} also shows how to integrate everything in NSGA-II. Moreover, this algorithm is ``pluggable'' in a sense that we can integrate it to any other elitist EMO algorithm. In the following section, we are going to see in details, how our opposite generation algorithm drastically improves the convergence rate.
%
\begin{algorithm}[tp]
\caption{NSGA-II with Opposition}
\label{algo:onsga2}
\begin{algorithmic}[1]
	\REQUIRE true PF extreme points $E^{\ast}$ from Algorithm \ref{algo:find-extreme-points}
	\STATE $N \leftarrow$ population size $|P_t|$
	\STATE $N_{\text{gen}} \leftarrow $ maximum generation
	\STATE $t \leftarrow 1$
	\WHILE{$t \le N_{\text{gen}}$}
		\STATE $P'_t \leftarrow$ randomly select 25\% solutions from $P_t$
		\STATE $E'_t \leftarrow$ construct pivot set $E'$ using algorithm \ref{algo:generate-pivot-points}
		\STATE $O_t \leftarrow \emptyset$
		\FOR{each solution $\mathbf{x_i} \in P'_t$}
			\STATE $S \leftarrow$ pick $k$ random solutions from $E'_t$
			\STATE $\mathbf{v} \leftarrow$ $\mathbf{v} \in S$ such that $\mathbf{v}$ is furthest from $\mathbf{x_i}$
			\STATE $d \leftarrow ||\mathbf{v} - \mathbf{x_i}||$
			\STATE $\mathbf{x_c} \leftarrow \mathbf{x_i} + \mathbf{U}[(\frac{3d}{4}, \frac{5d}{4})] \circ (\frac{1}{d}(\mathbf{x_i} - \mathbf{v}))$
			\STATE correct $\mathbf{x_c}$ using the variable bounds, if necessary.
			\STATE $O_t \leftarrow \{O_t \cup \mathbf{x_c}\}$
		\ENDFOR
		\STATE $P_t \leftarrow \{P_t \cup  E^\ast\}$
		\STATE $R_t \leftarrow \{P_t \cup Q_t\}$
		\STATE rank $R_t$ into fronts, $R_t \rightarrow \{\mathcal{F}_1, \mathcal{F}_2, \ldots, \mathcal{F}_n\}$
		\STATE $P_{t+1} \leftarrow \emptyset$
		\STATE $i \leftarrow 1$
		\WHILE{$|P_{t+1}| + |\mathcal{F}_i| \le N$}
			\STATE assign crowding distances on the front $\mathcal{F}_i$
			\STATE $P_{t+1} \leftarrow \{P_t \cup \mathcal{F}_i\}$
			\STATE $i \leftarrow i + 1$
		\ENDWHILE
		\STATE sort $\mathcal{F}_i$ in descending order using $\prec_n$
		\STATE $P_{t+1} \leftarrow$ the first $N - |P_{t+1}|$ solutions from $\mathcal{F}_i$
		\STATE $Q_{t+1} \leftarrow$ select, crossover and mutate $P_{t+1}$
		\STATE randomly insert all $x_i \in O_t$ into $Q_{t+1}$ with no overlapping $x_i$
		\STATE $t \leftarrow t + 1$
	\ENDWHILE
\end{algorithmic}
\end{algorithm}
%
%
\begin{figure*}[b!]
	\centering
	\subfloat[Convergence test for ZDT2 problem\label{subplot:zdt2-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt2-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for ZDT3 problem\label{subplot:zdt3-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-onsga2r-nsga2r-hvstat}}
	\hfill
	\subfloat[Convergence test for ZDT4 problem\label{subplot:zdt4-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt4-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for ZDT6 problem\label{subplot:zdt6-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt6-onsga2r-nsga2r-hvstat}}
	\caption{These plots illustrates the comparative analysis of the convergence rates for different 2-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2r is NSGA-II.}
	\label{plot:onsga2r-hv-zdt}
\end{figure*}
%
% Figure
\begin{figure}[tp]
\centering
\includegraphics[width=0.5\textwidth]{zdt1-onsga2r-nsga2r-hvstat}
\caption{The convergence test of Algorithm \ref{algo:onsga2} (onsga2r) vs. NSGA-II on problem ZDT1}
\label{plot:zdt1-onsga2r}
\end{figure}
%
\begin{figure*}[tp]
	\centering
	\subfloat[Exploration at generation 9 -- ZDT3 problem\label{subfig:zdt3-gen-9}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-gen-9}}
	\subfloat[Exploration at generation 22 -- ZDT3 problem\label{subfig:zdt3-gen-22}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-gen-22}}
	\hfill
	\subfloat[Exploration at generation 45 -- ZDT3 problem\label{subfig:zdt3-gen-45}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-gen-45}}
	\subfloat[Exploration at generation 6 -- ZDT4 problem\label{subfig:zdt4-gen-6}]{%
		\includegraphics[width=0.5\textwidth]{zdt4-gen-6}}
		\caption{This figure illustrates how our algorithm deterministically identifies which front needs to be explored first and gradually discovers the entire PF. The example here demonstrates a 3 cases of ZDT3 problem (Figure \ref{subfig:zdt3-gen-9}--\ref{subfig:zdt3-gen-45}). The orange dots represents the deterministically generated solutions that did not survived because they are weakly dominated. In the case of ZDT4 (Figure \ref{subfig:zdt4-gen-6}), we can see how the bias and gaps have been corrected by our approach.}
	\label{fig:zdt3-gap}
\end{figure*}
%

\section{Experiments with the Benchmark Problem Set}
\label{sec:onsga2r-zdt}
First we have tested the performance of Algorithm \ref{algo:onsga2} on \(5\) \(2\)-objective problems \cite{zdt-set}, namely ZDT1, ZDT2, ZDT3, ZDT4 and ZDT6, and we have set NSGA-II as the control. To maintain a fair comparison, we have compensated the extra function evaluations by the Algorithm \ref{algo:find-extreme-points} for the NSGA-II runs, and compared NSGA-II and Algorithm \ref{algo:onsga2} side by side. The performance measure for our test was Hypervolume (HV), and we are interested to see which algorithm can reach to a desired HV within less function evaluations (FE). For all problems, we have seen our algorithm can demonstrate a very steep convergence to the true PF, even when the extra FE from Algorithm \ref{algo:find-extreme-points} are compensated for NSGA-II. All the results are collected from 30 independent runs started with non-identical random seeds. In all plots, \textit{onsga2r} stands for Algorithm \ref{algo:onsga2}. The extra cost to find the extreme points are indicated with a ``T'' arrow on the x-axis. During computation of the HV measure, we have set the reference point to \(\{2.0,2.0\}\) for all problems except ZDT6, where it has been set to \(\{4.0, 4.0\}\)\footnote{The code that we have used to compute HV measure was taken from \url{http://www.wfg.csse.uwa.edu.au/hypervolume/index.html#code}, where the implementation assumes that all the objective values need to be on the one side of the reference point. For ZDT6, a closer reference point made the curves in the plots to be showing up very late at the end of x-axis.}.

The experiment with ZDT1 is illustrated in Figure \ref{plot:zdt1-onsga2r}, here we can see that the Algorithm \ref{algo:find-extreme-points} takes up to around \(1K\) of function evaluations. Given that, NSGA-II still lags behind with a multiple factors to reach the desired PF. We have seen similar effect on all the rest of the problems ZDT2, ZDT3, ZDT4 and ZDT6. Except for ZDT3, we can see some fluctuations due the disconnected nature of the true PF. All the plots for the rest of the problems are presented in Figure \ref{plot:onsga2r-hv-zdt}.

There is another interesting observation we have made, once this opposite point generation scheme is used, the search process becomes more focused and works in a more predictive manner. As an example, in the case of ZDT3 problem (where the true PF consists of 5 disconnected curves), the algorithm first tries to fill up the first partition and gradually moves to the next. The algorithm automatically detects which portion of the PF needs to be addressed first and try to fill the gaps by deliberately injecting points to the vicinity of those gaps. As a result our model can infer which objective is hard to solve and deterministically decides which one needs to be explored more. This scenario is illustrated in Figure \ref{fig:zdt3-gap}, where we can see how the point generation algorithm moves from one disconnected front to the next.
%
\begin{figure*}[tp!]
	\centering
	\subfloat[Convergence test for DTLZ1 problem\label{subplot:dtlz1-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz1-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for DTLZ2 problem\label{subplot:dtlz2-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz2-onsga2r-nsga2r-hvstat}}
	\hfill
	\subfloat[Convergence test for DTLZ3 problem\label{subplot:dtlz3-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz3-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for DTLZ4 problem\label{subplot:dtlz4-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz4-onsga2r-nsga2r-hvstat}}
	\hfill
	\subfloat[Convergence test for DTLZ5 problem\label{subplot:dtlz5-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz5-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for DTLZ6 problem, hypervolume values for our algorithm can be seen near the extreme top of the graph boundary.\label{subplot:dtlz6-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz6-onsga2r-nsga2r-hvstat}}
	\caption{These plots illustrates the comparative analysis of the convergence rates for different 3-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2r is NSGA-II.}
	\label{plot:onsga2r-hv-dtlz}
\end{figure*}
%

Moreover, our approach can also efficiently solve the issue of \textit{search trajectory bias}, if we look at the Figure \ref{subfig:zdt4-gen-6}, we can see that the new solutions are deterministically generated where the explorations are not done thoroughly yet.

\subsection{Experiments with the Scalable Problem Set}
\label{sec:onsga2r-dtlz}
In the next experiment, we have carried out the similar tests with the scalable problem sets -- DTLZ1, DTLZ2, DTLZ3, DTLZ4, DTLZ5 and DTLZ6 \cite{dtlz-set}. For all cases we have considered \(3\)-objectives. The control was NSGA-II results and similarly we compensate the measure with the extra FE to find extremes. All the results are collated from 30 independent runs. The reference point for HV computation has been set to \(\{2.0, 2.0, 2.0\}\) for DTLZ2, DTLZ4 and DTLZ5. For DTLZ1 it has been set to \(\{10.0, 10.0, 10.0\}\), for DTLZ3 it was \(\{15.0, 15.0, 15.0\}\) and for DTLZ6, it was \(\{4.0, 4.0, 4.0\}\). All the convergence plots are presented in the Figure \ref{plot:onsga2r-hv-dtlz}. 

Here we can see, in DTLZ1 and DTLZ3 our approach shows noticeable improvement, and for DTLZ6 the opposite point generation offers even greater improvement. However, for DTLZ2, DTLZ4 and DTLZ5 the opposition scheme does not offer any improvement. What we have seen for these problems, NSGA-II does not face much difficulties to reach to the true PF therefore the outcome stays same even if we introduce extreme points to guide the search. For example DTLZ6 is harder than DTLZ5\footnote{DTLZ5 and DTLZ6 are basically the same except an exponential growth added to the \(g\) function}, as a result, our approach shows even better efficacy in solving harder problems. There is another interesting fact that we need to acknowledge -- there is no way that our approach will degrade the performance of the host algorithm (i.e. NSGA-II), since all the points we generate are no worse than the existing solutions in the population. The opposition scheme invariably adds improvements on the convergence if there is any. 
%
\begin{figure*}[pb!]
	\centering
	\subfloat[ZDT4 problem\label{subplot:zdt4-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{zdt4-onsga2r-nsga2re-hvstat}}
	\subfloat[DTLZ1 problem\label{subplot:dtlz1-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{dtlz1-onsga2r-nsga2re-hvstat}}
	\hfill
	\subfloat[DTLZ5 problem\label{subplot:dtlz5-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{dtlz5-onsga2r-nsga2re-hvstat}}
	\subfloat[DTLZ6 problem, hypervolume values for our algorithm can be seen near the extreme top of the graph boundary.\label{subplot:dtlz6-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{dtlz6-onsga2r-nsga2re-hvstat}}
		\caption{These plots illustrates the comparative analysis of the convergence rates for different 2 and 3-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2re is the NSGA-II equipped with extreme points.}
	\label{plot:nsga2re-hv}
\end{figure*}
%
% Figure
\begin{figure}[tp]
\centering
\includegraphics[width=0.5\textwidth]{dtlz2-longvar}
\caption{The experiment with the varying variable length for DTLZ2 problem. `onsga2r' stands for our approach and `nsga2r' is the NSGA-II algorithm, \(n\) is the variable size. NSGA-II is also compensated for the extra function evaluations to find the true PF extremes. The lines for our algorithm shows the \textit{minimum} hypervolume achieved in each run; and for NSGA-II, we have taken the \textit{maximum} of it.}
\label{plot:longvar}\vspace{-3.0pt}
\end{figure}
%

\subsection{Expanding the Search Space} 
\label{subsec:longvar}
For DTLZ2, DTLZ4 and DTLZ5 problems, we have already seen that the convergence gain was not noticeable. However, still we are not clear how our model will behave if the problem difficulty is increased. To investigate, we have increased the number of variables \(n\) to see if we can improve. For example we have picked one problem like DTLZ2 and done the same experiments with varying number of design variables. The standard setting for DTLZ2 is \(n = 12\), we have changed this length from \(12\) to \(96\) every time by multiple of \(2\). The outcome of this test is quite interesting -- the applicability of our approach is increased with the number of variables, and this effect is identical for DTLZ4 and DTLZ5 as well. This result for DTLZ2 is presented in the Figure \ref{plot:longvar}, here we can see at \(n = 96\), our approach shows the most gain in the convergence speed-up, and if we make \(n\) even bigger, the trend becomes more conspicuous. Moreover, in Figure \ref{plot:longvar}, we have shown \textit{minimum} hypervolume achieved with our approach and the \textit{maximum} possible hypervolume achieved by the NSGA-II algorithm.

For this experiment, we did not use MADS algorithm to find the extreme solutions, although these problems have local optima. The MADS algorithm is good for finding more accurate extreme points for small problems with local optima -- with smaller function evaluations, however, the performance of MADS degrades as the number of variables gets bigger, where a budgeted evaluation is a requirement. Our empirical investigation shows that for large variable space, IP methods give reasonably close (at least that are good for our purpose) extreme points within the acceptable function evaluations.\vfill

\subsection{Next Experiment: NSGA-II Equipped with Extreme Points}
\label{subsec:nsga2re}
We were also very curious to see, what if we introduce the extreme points to the NSGA-II so that it can utilize them to converge to the true PF. In this case, we compute the pivot points from the initial population, inject them and let the NSGA-II run. Here NSGA-II does not employ any opposite point generation scheme. All the test parameters were kept same as before and the results are summarized in the Figure \ref{plot:nsga2re-hv}. Here, we can see that the convergence rate is improved in some cases, but NSGA-II with extreme points shows a noticeable variance during the convergence and our approach is more robust (i.e. shows less variance). This is because our approach generate new points in a very deterministic and predictable manner and the NSGA-II tries to emulate this by applying mutation/crossover. We also need to remember that we set aside only 25\% of the original population to be subjected to opposition. We only add a subset of our original results in the Figure \ref{plot:nsga2re-hv}, since all of them shows the similar trend as in Figure \ref{plot:onsga2r-hv-zdt} and \ref{plot:onsga2r-hv-dtlz}.

In the next sections we are going to experiments with more interesting what-if analysis -- how does our model perform what if the true PF extremes are not found, how does the deterministically generated points (i.e. opposite solutions) contribute to the search mechanism etc.
%
\begin{figure*}[pb!]
	\centering
	\subfloat[ZDT4 problem\label{subplot:zdt4-weak}]{%
		\includegraphics[width=0.49\textwidth]{zdt4-weak}}
	\subfloat[DTLZ1 problem\label{subplot:dtlz1-weak}]{%
		\includegraphics[width=0.49\textwidth]{dtlz1-weak}}
	\hfill
	\caption{These plots illustrates the comparative analysis of the convergence rates for different 2 and 3-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2r is the NSGA-II. Here the our algorithm starts with a deliberately injected weakly dominated extreme solutions. For ZDT4 it is \(\{(1.0, 42.0), (0.0, 68.0)\}\) and for DTLZ1 it is \(\{(570.4, 0.0, 12.2),(0.0, 251.4, 0.0),(0.0, 0.0, 44.8)\}\).}
	\label{plot:weak-hv}
\end{figure*}
%
%
\begin{table*}[tp!]
\caption{Mean Static Survival Rates for Different Problems}
\label{table:survival}
\centering
{\renewcommand{\arraystretch}{1.5}
\begin{tabular}{l|llllllll|lll}
Problems	& ZDT1            & ZDT2            & ZDT3           & ZDT4            & ZDT6            & DTLZ1           & DTLZ3           & DTLZ6           & DTLZ2           & DTLZ4    & DTLZ5	\\ \hline
Improvement Seen            & \textbf{Yes}  & \textbf{Yes}  & \textbf{Yes} & \textbf{Yes}  & \textbf{Yes}  & \textbf{Yes}  & \textbf{Yes}  & \textbf{Yes}  & No              & No       & No      \\ \hline
	Static Survival Rate (\(\%\)) & \textbf{33.5} & \textbf{33.3} & 13.8           & \textbf{31.0} & \textbf{32.6} & \textbf{32.4} & \textbf{27.7} & \textbf{38.3} & \textbf{28.1} & 19.1 & \textbf{29.8} \\ \hline
\end{tabular}}
\end{table*}
%
\section{Experiment with The Weakly Dominated Extreme Points}
\label{sec:weak-extremes}
In this paper, all the experiments were carried out on the standard benchmark problems popular among the EMO practitioners, however in other situation, it may be very hard to find the true PF extremes. In this experiment we will try to address this issue by deliberately setting the extreme points as weakly dominated solutions of varying distances from the true PF extremes. More specifically, for ZDT1 problem, the true PF extremes are located at \(\{(1.0, 0.0, (0.0, 1.0)\}\), but we will start the algorithm with \(\{(2.0, 0.0), (0.0, 2.0)\}\), \(\{(4.0, 0.0), (0.0, 4.0)\}\) etc. and see if we can still keep the performance (or if degrades, how do they degrade).

The results are shown for problems ZDT4 and DTLZ1 in Figure \ref{plot:weak-hv}, here we can see that for ZDT4 problem our approach runs with more variance however, the mean/median hypervolume values are still better than the NSGA-II runs. For DTLZ1, we can see a bit degrading trend demonstrated by our approach, however still we are better off in-terms of mean/median hypervolume measure. This experiment says that our approach is still viable even if the extreme points are \textit{very} far from the true PF-extremes.
% Figure
\begin{figure}[t]
\centering
\includegraphics[width=0.5\textwidth]{zdt1-survival}
\caption{The survival rate problem ZDT1 over the generations, we can see the highest peek at generation \(2\) and settles down to \(33.5\%\) around generation \(20\).}
\label{plot:zdt1-survival}
\end{figure}
%
\section{Survival of The Opposite Solutions}
\label{sec:survival}
In the next part, we will see how the deterministically generated solutions survives the selection mechanism at the line 28 in Algorithm \ref{algo:onsga2}. To do this we assign flags to the generated opposite solutions in every generation and count how many of them are passing through the selection phase. Interestingly, in all of the cases, this survival rate is very high during the initial generations and steeply settles down to \(\sim30\%\). This was really confounding to notice why this rate almost always settles down to a specific number \(\sim30\%\), especially in those cases when the opposition approach shows a better convergence pay-offs. This scenario is presented in the Figure \ref{plot:zdt1-survival}, where the highest survival rate (\(94\%\)) has been achieved at generation \(2\) and reached the equilibrium at \(33\%\). In order to make this illustrations more compact, we present these statistics in the Table \ref{table:survival}.

Please also note that all the experiment data were collated from \(30\) independent runs, therefore the survival rate is calculated as the mean of those \(30\) runs at each generation.\vfill \eject

\section{Computation Cost}
\label{sec:big-o}
The principal overhead for our approach is the complexity incurred by the Algorithm \ref{algo:find-extreme-points}, where the computational cost comes from the IP and the MADS algorithm. However, this IP or MADS function call is a one-pass process. Therefore, we are going to see the how the rest of the algorithm imposes the extra computational overhead on the host algorithm (i.e. NSGA-II). The line 6 in Algorithm \ref{algo:onsga2} is a call to Algorithm \ref{algo:generate-pivot-points}. The expensive part of this algorithm is line 11 -- which is in fact, a linear function of \(N\) (\(N = \text{population size}\)), i.e. \(\Theta(N)\) and all the other terms are function of \(k\) (\(k = \text{no. of objectives}\)). Therefore the overall complexity for the Algorithm \ref{algo:generate-pivot-points} is \(O(N)\). The loop 8--14 takes exactly \(\Theta(\frac{N}{4}) < O(N)\), the same goes with line 29. Therefore, our approach does not add any extra computational cost to NSGA-II algorithm.

\section{Conclusions and Future Works}
\label{sec:conclusion}
The main contribution of this paper is the incorporation of opposite point generation scheme in a different perspective. We have shown that a simple and a deterministic approach can aid to the EMO optimization algorithm in a very interesting way. Our approach is also easy to implement and offers less overhead to the host algorithm. Our approach can also correct the search bias introduced by the problem difficulty in an automated and predictable manner. We have also seen that the usefulness of our approach becomes more salient with the increasing level of problem difficulty. Even though we have carried out a quite extensive study of our model on a variety of benchmark problems, but we did not do any study on real world problems. The original idea of the opposition based optimization is quite interesting, however it could be made more of it if this idea is utilized in a more meaningful way -- we think this is the main contribution of our study.  

However, in future we want to address some more interesting issues with our current study, especially in the ``many-objective'' problems. As we have seen, our approach spends a good portion of the function evaluations to compute the extreme points for each objective separately. This overhead becomes more of a problem when the number of objective is multiplied. In such cases, our current model might not be much useful. Moreover, finding the extreme points itself comes with its own set of problems -- i)finding the accurate extreme points are not guaranteed ii)the identification of extremes becomes more problematic when the true PF is a disconnected front iii) notionally, the extreme points are harder to find than any other non-extreme points on the true PF as ``being extreme'' could be interpreted as another constraint. Therefore, dependency on the extreme points, we think a limitation of our approach.

In the future work, we are going to address these issues. Moreover, we think there are also a possible scope in changing the idea \textit{opposition} for reference point based many-objective algorithms like MOEA/D and NSGA-III \cite{nsga3-main-p1}\cite{nsga3-main-p2}. In the future research, we hope to investigate these ideas. \vfill \eject 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

\subsection{Subsection Heading Here}
Subsection text here.

% needed in second column of first page if using \IEEEpubid
%\IEEEpubidadjcol

\subsubsection{Subsubsection Heading Here}
Subsubsection text here.


% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.

\section{Conclusion}
The conclusion goes here.

% if have a single appendix:
%\appendix[Proof of the Zonklar Equations]
% or
%\appendix  % for no appendix heading
% do not use \section anymore after \appendix, only \section*
% is possibly needed

% use appendices with more than one appendix
% then use \section to start each appendix
% you must declare a \section before using any
% \subsection or using \label (\appendices by itself
% starts a section numbered zero.)
%


\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.

% you can choose not to have a title for an appendix
% if you want by leaving the argument blank
\section{}
Appendix two text goes here.


% use section* for acknowledgment
\section*{Acknowledgment}


The authors would like to thank...


% Can use something like this to put references on a page
% by themselves when using endfloat and the captionsoff option.
\ifCLASSOPTIONcaptionsoff
  \newpage
\fi



% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

\end{comment}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{IEEEabrv,report}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
% \begin{thebibliography}{1}
% 
% \bibitem{IEEEhowto:kopka}
% H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%   0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
% 
% \end{thebibliography}

% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
% or if you just want to reserve a space for a photo:

% \begin{IEEEbiography}{Michael Shell}
% Biography text here.
% \end{IEEEbiography}

% if you will not have a photo at all:
% \begin{IEEEbiographynophoto}{John Doe}
% Biography text here.
% \end{IEEEbiographynophoto}

% insert where needed to balance the two columns on the last page with
% biographies
%\newpage

% \begin{IEEEbiographynophoto}{Jane Doe}
% Biography text here.
% \end{IEEEbiographynophoto}

% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.

%\vfill

% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}



% that's all folks
\end{document}


