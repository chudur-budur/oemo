% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate-05-2015}

% My packages
\usepackage{comment}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{lipsum}
\usepackage{subfig}
\usepackage{rumathmacros}

% all image paths
\graphicspath{%
	{./results/zdt1/}%
	{./results/zdt2/}%
	{./results/zdt3/}%
	{./results/zdt4/}%
	{./results/zdt6/}%
	{./results/dtlz1/}%
	{./results/dtlz2/}%
	{./results/dtlz3/}%
	{./results/dtlz4/}%
	{./results/dtlz5/}%
	{./results/dtlz6/}%
	{./results/dtlz7/}%
	{./figs/}%
}

\begin{document}

% Copyright
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
% \doi{10.475/123_4}

% ISBN
% \isbn{123-4567-24-567/08/06}

%Conference
% \conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}

% \acmPrice{\$15.00}

%
% --- Author Metadata here ---
% \conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Constructing the Pareto Front using Limited Information:\\A Case of the Opposition based Solution Generation Scheme%
% \titlenote{(Produces the permission block, and
% Copyright information). For use with
% SIG-ALTERNATE.CLS. Supported by ACM.}%
}
% \subtitle{[Extended Abstract]
% \titlenote{A full version of this paper is available as
% \textit{Author's Guide to Preparing ACM SIG Proceedings Using
% \LaTeX$2_\epsilon$\ and BibTeX} at
% \texttt{www.acm.org/eaddress.htm}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

% \numberofauthors{8} %  in this sample file, there are a *total*
\numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
Author1\\
%\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{author1 department}\\
       \affaddr{author1 university}\\
       \affaddr{author1 country}\\
       \email{author1@email}
% 2nd. author
\alignauthor
Author2\\
%\titlenote{The secretary disavows any knowledge of this author's actions.}\\
       \affaddr{author2 department}\\
       \affaddr{author2 university}\\
       \affaddr{author2 country}\\
       \email{author2@email}
% 3rd. author
\alignauthor
Author3\\
% \titlenote{This author is the one who did all the really hard work.}\\
       \affaddr{author3 department}\\
       \affaddr{author3 university}\\
       \affaddr{author3 country}\\
       \email{author3@email}
% \and  % use '\and' if you need 'another row' of author names
% % 4th. author
% \alignauthor Lawrence P. Leipuner\\
%        \affaddr{Brookhaven Laboratories}\\
%        \affaddr{Brookhaven National Lab}\\
%        \affaddr{P.O. Box 5000}\\
%        \email{lleipuner@researchlabs.org}
% % 5th. author
% \alignauthor Sean Fogarty\\
%        \affaddr{NASA Ames Research Center}\\
%        \affaddr{Moffett Field}\\
%        \affaddr{California 94035}\\
%        \email{fogartys@amesres.org}
% % 6th. author
% \alignauthor Charles Palmer\\
%        \affaddr{Palmer Research Laboratories}\\
%        \affaddr{8600 Datapoint Drive}\\
%        \affaddr{San Antonio, Texas 78229}\\
%        \email{cpalmer@prl.com}
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
% \additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
% email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
% (The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
\date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
In this paper we investigate a curious example of opposition based solution generation applied to an evolutionary multi-objective optimization (EMO) algorithm, namely on NSGA-II. In this paper we will see how the concept of Opposition Based Learning (OBL) can be reformulated to suite the Multi-objective Optimization (MOP) settings. We have devised a simple and an intuitive approach for OBL so that it can be applied to any elitist EMO algorithm. We have also conducted an in-depth analysis of the efficacy of our approach to a wide range of benchmark MOP test functions. We have also proposed a definitive guideline to how to find the extreme solutions on the true Pareto-front. Our proposed model utilizes a deterministic solution generation scheme that is guided by the opposite traits imposed on the current population individuals. %Our study have also addressed some boundary issues -- such as the quantitative applicability of the opposite solutions generated by our approach.
\end{abstract}


%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
% \begin{CCSXML}
% <ccs2012>
%  <concept>
%   <concept_id>10010520.10010553.10010562</concept_id>
%   <concept_desc>Computer systems organization~Embedded systems</concept_desc>
%   <concept_significance>500</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010575.10010755</concept_id>
%   <concept_desc>Computer systems organization~Redundancy</concept_desc>
%   <concept_significance>300</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10010520.10010553.10010554</concept_id>
%   <concept_desc>Computer systems organization~Robotics</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
%  <concept>
%   <concept_id>10003033.10003083.10003095</concept_id>
%   <concept_desc>Networks~Network reliability</concept_desc>
%   <concept_significance>100</concept_significance>
%  </concept>
% </ccs2012>  
% \end{CCSXML}
% 
% \ccsdesc[500]{Computer systems organization~Embedded systems}
% \ccsdesc[300]{Computer systems organization~Redundancy}
% \ccsdesc{Computer systems organization~Robotics}
% \ccsdesc[100]{Networks~Network reliability}


%
% End generated code
%

%
%  Use this command to print the description
%
\printccsdesc

% We no longer use \terms command
%\terms{Theory}

% \keywords{ACM proceedings; \LaTeX; text tagging}
\keywords{Evolutionary Multiobjective Optimization, Opposition Based Learning (OBL)}

\section{Introduction}
In the recent years, the idea of Opposition Based Learning (OBL) has been enjoying a noticeable attention among the AI and OR practitioners. The idea of OBL is to accelerate the learning rate (or convergence rate) by imposing an opposite estimate of the current solution, and deliberately introducing them to influence the search trajectory. This idea was first introduced in \cite{obl-main} and has been demonstrated its effectiveness in different scenarios -- from Reinforcement Learning (RL) \cite{obl-rl}, Differential Evolution (DE) \cite{ode-main} to robotics \cite{ode-robot}. 

In all of the cases, the OBL comes into play specially during the initialization phase of the learning algorithm (or optimization algorithm), the argument behind this strategy is that a completely arbitrary (i.e. blind) initialization is no better than an informed boot-strap. Since a random sampling or selection of solutions from a given population has the possibility of visiting or even revisiting unpromising regions of the search space. In \cite{ode-main}, it has also been demonstrated that the chance of such revisits are lower in the case of opposite than it is for purely random initialization. There is also a formal proof that shows that, in general, the opposite estimations are more likely to be closer to the optimal solution than the completely arbitrary ones \cite{theory-1}. A more details of a formal probabilistic analysis of opposition based learning can also be found in \cite{theory-2}.

Moreover, especially for the case of optimization algorithms, it has been demonstrated that keeping a small ratio of solutions with the opposite estimate helps to converge better \cite{opbil} -- and most of the recent studies are inspired by this approach. For example, in \cite{omoead} similar strategy has been used in the case of MOEA/D \cite{moead-main}. We have also seen identical examples in \cite{omode}. Another relevant study can be found in \cite{opso}, where the opposition based initialization has been tested with the Particle Swarm Optimization (PSO) scenario to induce a better convergence. Given all of these studies, still we could not find a good example of this idea applied to the Evolutionary Multi-objective Optimization (EMO) cases -- more importantly -- in a more meaningful and precise way. In this study we will try to fill this gap in an interesting and in a simpler way. 

In our approach, we will address this idea of \textit{opposition} in a different perspective, we will classify the (not to be confused with the term ``classification'' in machine learning domain) solutions with respect to some \textit{desired traits} that we will like to have. Then we will use this information to deterministically generate new solutions in a most viable locations in the search space -- and this operation will be dictated by our special notion of opposition. In fact, our approach is somewhat similar in spirit to the previous studies done in \cite{sts-1}, \cite{sts-2} and \cite{directional-mutation}. Except the fact that our approach is extremely simple and does not assume any special property on the underlying search space, moreover, our approach does not build a computationally expensive models as done in \cite{search-history}\cite{segment-search}.

This paper is organized as follows -- first we will discuss why this idea of OBL needs to be reinterpreted for the Multi-objective Optimization (MOP) setting. Next we discuss one interesting limitation that most EMO algorithms suffer from -- the \textit{search trajectory bias}, and also give some argument on why such hindrance becomes inevitable. Then we will discuss how the idea of OBL can come into rescue. In our model, we generate the opposite points in a strictly deterministic way, by carrying out the arbitration of \textit{opposition} in a different (and a more MOP relevant manner). To do this, we utilize the extreme solutions on the true Pareto-front (PF), and the next section discusses how to find them efficiently. After that we will describe our main algorithm in details. Then we will show our experiments with different benchmark MOP problem sets. 

We will also see some boundary issues with our models -- like how the opposite points get utilized during the run, and some what-if analysis by integrating our models into the canonical EMO algorithm, namely in NSGA-II \cite{nsga2-main}. We will also see how this approach becomes more useful if the underlying search space becomes more complex or computationally more expensive to explore. Then we conclude our study by discussing some future guidelines to extend our idea.

\section{An Alternative Interpretation of Opposition}
\label{sec:alternative-interpretation}
As we have already discussed in the previous section, in most of the studies, the idea of \textit{opposition} is employed as an incorporation of new solutions with a certain kind of \textit{opposite traits} into the existing population. Such traits could be interpreted in terms of different problem domain perspectives. For example, the \textit{opposite} solutions could be -- i) the ones with complete opposite representation from the current best individual, ii) the ones with the opposite estimates from the other spectrum of the variable bounds (i.e. in the case of real valued optimization). However, the injection of the opposite solutions could cause a re-route from the continuing search trajectory and thus could be a misleading operation -- in a sense that the opposite solutions might be useful given that the search space follows a desired pattern. 

For example, if the task is to solve the N-queen problem, then the opposite representation of the current best can result into another valid global optima. One can easily verify this by computing the reverse assignment of queens from a existing optimal solution; and it will eventually take us to another global optima. This observation also assumes that the search space is multi-modal, following from the fact that the reverse representation of the current best solution needs to be an optimum for another peak of the search space. Therefore, most of the standard opposition based algorithms inject the opposite solutions during the optimization start-up; or maintain a constant (generally low) ratio of opposite points throughout the run. Therefore, the standard opposite injection scheme could only be effective given the two assumptions on the underlying search space are valid -- multi-modality and the solution symmetry. For this reason, what we think -- such approach is quite unwieldy to directly incorporate into a large scale numerical optimization problems, e.g. multi-objective optimization problems (MOPs).

Moreover, we have also seen some examples of opposition based algorithm for Q-learning/TD-learning like scenarios \cite{obl-rl}. Similar argument can be made, as the reinforcement-learning algorithms are inherently greedy (as they rely on the Bellman's optimality principle). And the opposite actions during the learning phase introduces a noise; so that the search can branch out to alternative choices. In that sense, we can say that the injection of opposite solutions can be considered as a different form of \textit{variation operator} in population based stochastic search. 

However, in the case of complex problem solving, the existing opposition based solution generation schemes may not be always effective. As we think, they are ``blind'' -- the opposite solutions are generated from the current best in an arbitrary manner. The existing approaches do not take account other important requirements that a good solution needs to be abide by. For example, if we arbitrarily create an completely opposite solution from the current best without considering any constraint, we could end up with a solution with a worst fitness value or a solution that violates constraints. Therefore, we think this idea of opposition needs to be revised, so that we can model the opposite traits as the choice between the \textit{good} and \textit{bad} solutions.

Moreover, in the numerical optimization scenarios, we hardly have rooms to make any assumption about the multi-modality of the search space and/or the symmetry of the solution representation (i.e. unlike such assumptions could be made about the N-queen problem). Therefore, in this paper, we have revised the notion of opposition in terms of the preference criteria imposed on a solution. For example, most evolutionary multi-objective optimization (EMO) algorithms aim to maximize two principal properties -- i) the convergence and ii) the diversity, since the quality of a MOP solution depends on these two factors. Therefore, let us re-consider the opposite point generation/injection in a different perspective --
\begin{itemize}
	\item Opposite Convergence: A solution \textit{far} from the true Pareto-front is \textit{opposite} to any solution that is \textit{closer} to the true Pareto-front.
	\item Opposite Diversity: An \textit{isolated} solution on the true Pareto-front is \textit{opposite} to a \textit{crowded} solution. 
\end{itemize}

By taking the above two principles into account, we will deterministically generate opposite solutions during the search. Obviously, the deterministic point generation scheme will only consider an opposite trait that is \textit{good}. In the next section we will see, how the existing EMO algorithms shows the limitations in maintaining this two opposite traits during the search (i.e. solution generation) process.  

% Figure
\begin{figure}[!pb]
	\centering
	\includegraphics[width=0.5\textwidth]{zdt4-bias}
	\caption{The effect of the \textit{search trajectory bias} could be seen when we try to solve ZDT4 problem with NSGA-II. Here we can see a long streak of crowded solution near the objective \(f_2\), where the distribution of solutions near the objective \(f_1\) is extremely sparse.}
	\label{fig:zdt4-unbalanced-snapshot}
\end{figure}
%
\section{Limitations with the Canonical EMO Algorithms: The Search Trajectory Bias}
\label{sec:limitation-canonical}
Most of the standard EMO algorithms (e.g. NSGA-II, SPEA-II \cite{spea2-main} etc.), are elitist by design. They are also ``opportunistic'' in a sense that the population always try to converge to a particular portion of the Pareto-front (PF) which seems to be easier to solve at that moment. They also show preferences over a certain objective function which needs less exploration than the other. We can see such bias in the search when we try to solve the ZDT4 problem using NSGA-II. In this case, the first objective is easier to optimize than the second one, the readers can verify this fact from the Figure \ref{fig:zdt4-unbalanced-snapshot}. Therefore, the search trajectory deliberately accumulates more points over the first objective to optimize one particular portion of the Pareto-front. Moreover, while putting more solutions to the vicinity of one particular objective axis, the search trajectory looses the uniformity by forming a crowded streak of points along that axis; on the other hand we can see that there is almost no solution on the other spectrum of the objective space. This kind of non-symmetric search behaviour is, we think, causes a hindrance to the optimization procedure. Therefore, it would be helpful if we could selectively inject points during the search where the solution distribution is more sparse. In addition, we also think that this biased nature of the search trajectory could degrade with the addition of more objective functions. Moreover, this could also lead to a stagnation on the local optima, given that the search space has a lot many of them.

Given this specific scenario, now the main problem is to devise a way to deterministically generate points where the distribution of the solution is sparse. Here we assume that the lesser the number of solutions in a vicinity of objective \(f_i\), the harder it is to solve. This would be easy if we know the exact mapping of the design variable to objective values -- however such mapping is always unavailable and above all it is very expensive to infer. Another way could be to mutate the points where the solution is more sparse, but we think as the original algorithm already goes through such step, it is not going to be very effective\footnote{However, in the section \ref{subsec:nsga2re} we will demonstrate this fact that just mutating the sparse solutions does not help much.}. 

In this paper we are going to demonstrate a very effective approach to address this issue, we will show how we can maintain a balanced distribution of solutions that is parallel to the true PF. The proposed approach is also extremely effective in fast converging to the true PF as well.   

\section{The Deterministic Opposite Point Generation Scheme}
\label{sec:generation-scheme}
As we have discussed in the section \ref{sec:alternative-interpretation}, we will utilize the so-called notion of \textit{opposition} to deterministically generate points into strategically useful places on the search space. In principle, we do not assume any exact mapping over the design variables to objective values, and we apply a linear translation to achieve our goal effectively\footnote{As a matter of fact, we will also see in the later sections that such opposite points are generally \(\sim 30\%\) useful in most cases and they are more effective during the initial generations -- which is also a very interesting finding.}. In essence, instead of considering \textit{sparsity} and \textit{crowd} as two opposite traits, our method can impose any criteria like \textit{being `x'} and \textit{being `y'} as two opposites. Being said that, linear translation is a simplest way to deterministically generate \textit{`x' like} solutions from \textit{`y' like} ones. 

So, the initial step is to infer the true PF before starting the actual optimization run. To do this, we depend on barely \(k\) number (\(k = \text{number of objectives}\)) of extreme (or near extreme) points on the true PF since we can safely assume that the population will eventually reach to the vicinity of those extreme points in the end. Moreover, the extreme points will be used as a pivot to arbitrate between the opposite traits over the existing solutions. Also note that we are not going to deterministically define which portion of the search space is less easy (or hard) and so forth -- we will try to devise a technique that will automatically address and solve such issues on the fly.

Another reason to fixate over the \(k\) extreme points is that we also wanted to keep the algorithm simple so that it can only utilize the ``minimal information'' of the true PF. We also think it's valid to assume that any PF could be bounded by at least \(k\)-extreme points for any \(k\)-objective problem. Although, if we could supply other intermediary points on the true PF, we will be able to see a better performance gain with the existing model, however supply of \(1\) extra true PF solution comes with an added cost of extra function evaluations. As the extreme (or near extreme) points are the pivot to define the notion of \textit{opposite} in our case, we will start the next section by discussing how to find them efficiently.

\subsection{Finding the Extreme Points}
\label{sec:find-extreme-points}
Extreme points on the Pareto-front could be found using global search as well \cite{nadir-estimation}, however our goal was to save the extra computational cost as much as possible\footnote{The readers might be aware that efficiently finding the extreme points on the true Pareto-front is itself a separate research problem.}. Therefore, we resort to the classical single-objective optimization methods to solve this problem. Our choice of such algorithms were limited to, namely, the Interior Point (IP) method and the Mesh Adaptive Direct Search (MADS)\footnote{We have used the \texttt{fmincon()} and the \texttt{patternsearch()} routine in MATLAB (v. R2014a) for IP method and MADS respectively.}. As we also did not want to spend the valuable function evaluations for this purpose, we have conducted this extreme solution search as a fixed budget operation. Depending on the difficulty of the problems, appropriate routine parameters were empirically found out and they are problem dependent. These settings can be summarized as follows: 
%
\begin{itemize}
	\item If the problem has no local optima then we use IP method (i.e. \texttt{fmincon()}), it has been found to be comparatively less expensive even if the variable size is large.
	\item If the problem has local optima, MADS (i.e. \texttt{patternsearch()}) is faster for finding more accurate extreme points. However, if the number of objective is $k > 2$, then these settings are found to be more useful:
		\begin{itemize}
			\item \texttt{InitialMeshSize:} \(1/\text{population size}\)
			\item \texttt{Search Method:} \texttt{@MADSPositiveBasis2N} to start searching with $2N$ random directions, where $N =$ number of variables.
			\item and keeping \texttt{CompletePoll:} to \texttt{on} and\\ \texttt{CompleteSearch:} to \texttt{on}
		\end{itemize}
\end{itemize}
%
The readers should be aware that the algorithm parameter that we have found is not a general setting, they have been set according to the problem structure, so they are subjected to empirical investigations and the problem domain-knowledge. 

The actual extreme point computation algorithm was conducted in two steps -- given a particular objective function \(f_i\), first we try to solve it directly using either IPM or MADS (depending on the problem type); then after some \(\frac{T}{2}\) iterations once we find a reference solution \(\mathbf{z}\) that is hopefully close to \(f_i\)'s optima, then we construct a so-called Augmented Achievement Scalarizing Function (AASF) \cite{asf} from \(f_i\) as \(f_{\text{aasf}} = \max_{j=1}^k w_j(f_j(\mathbf{x}) - z_j) + \rho \sum_{j=1}^k w_j(f_j(\mathbf{x}) - z_j)\) and solve it again for \(\frac{T}{2}\) iterations. Here, we set \(w_i = 0.9\), \(w_{j \neq i} = \frac{1}{10(k-1)}\) and \(\rho = 0.0001\). 

To limit the function evaluations, we kept \(T\) to a constant value (as a budget). For all problems, we have fixed this maximum iteration count to the \(\frac{1}{4}\)-th of the total generation specified. More precisely, $T = \frac{1}{k}(\frac{1}{4}N_p N_{\text{gen}})$, where $k = \text{no. of objectives}$, $N_p = \text{population size}$ and $N_{\text{gen}} = \text{maximum generation}$. A basic listing for this routine is presented in Algorithm \ref{algo:find-extreme-points}. The set of the extreme points \(E^\ast\) generated from this algorithm may not contain all the unique solution, and also they might not be the true extreme always, they can be weakly dominated solutions by the true PF extremes. However, our approach can utilize them efficiently to converge to the true PF extremes.
%
\begin{algorithm}[!tp]
\caption{Find Extreme Points}
\label{algo:find-extreme-points}
\begin{algorithmic}[1]
	\STATE $k \leftarrow$ no. of objectives
	\STATE $N_p \leftarrow$ population size
	\STATE $N_{\text{gen}} \leftarrow$ maximum generation
	\STATE $T \leftarrow \frac{1}{k}(\frac{1}{4}N_p N_{\text{gen}})$
	\STATE $E^\ast \leftarrow \emptyset$, an empty solution set
	\FOR{$i$ from $1$ \TO $k$}
		\STATE $f_i \leftarrow$ $i$-th objective function
		\STATE $x_i \leftarrow $ random initial vector
		\REPEAT
			\STATE $x_i \leftarrow$ solve $f_i$ with IP method (or MADS) 
		\UNTIL{$\frac{T}{2}$ function evaluation reached}
		\STATE $f_{\text{aasf}} \leftarrow $ construct AASF function from $f_i$
		\REPEAT
			\STATE $x_i \leftarrow$ solve $f_{\text{aasf}}$ with  IP method (or MADS)
		\UNTIL{$\frac{T}{2}$ function evaluation reached}
		\STATE $E^\ast \leftarrow \{E^\ast \cup x_i\}$
	\ENDFOR
	\RETURN $E^\ast$
\end{algorithmic}
\end{algorithm}
%
\subsection{The Opposite Solution Generation Algorithm}
\label{sec:generate-pivot-points}
Once the extreme points are discovered, now we utilize them to generate the so-called \textit{opposite} points during the main evolutionary runs. On each generation, we select 25\% of the best individuals (front-wise) from the current population and deterministically change them to generate opposite solutions -- in such a way that we can address the strategically preferable places. And to conduct this variation, we will utilize the points in the set \(E^\ast\) as pivot points. We call these points as ``pivot'' since we will selectively try to generate points around these pivots. However, before doing this, we will \textit{refine} our pivot points \(E^\ast\) in a certain way. 

The \textit{refinement} starts by finding the current population extreme points \(E_c\) and merging them with the set \(E^\ast\) such that \(E = \{E_c \cup E^\ast\}\). Next we apply the non-dominated sort on \(E\) to find the Pareto-front within this set. We apply this sorting because we are not still sure if \(E^\ast\) contains true PF extremes. This sorting will keep the true extreme points if ones are found in the later generations. After this step, we select the points from \(E\) that are on the best front and with \(\infty\) crowding distances\footnote{By ``crowding distance'', we mean the inter-solution distances computed in NSGA-II.}. Lets denote these selected points as \(E'\). Now at this point, two situations are possible:
%
\begin{itemize}
	\item The set \(E'\) contains only the solutions \(E^\ast\) while we are in the initial generations, or
	\item The set \(E'\) contains the solutions \(E_c\) while we are in the later phase of the generations, where \(E_c\) are the true PF extreme. 
\end{itemize}
%
However, during the intermediate generations, it can also happen that we may include some solutions into \(E\) that weakly dominate a subset of points already in \(E\), this inclusion will reduce the expected spread of the pivot points -- that may diminish the effect of maintaining the diversity. For example, if the actual true PF is a broken Pareto-front, and if \(E\) contains the extreme points from one broken edge, then we need to expand the current edges so that the refinement procedure can include points from the further extreme ends. Therefore, if there exist a point in \(E - E'\) that is on the best front and also weakly dominated by any point in \(E'\), then we replace the weakly dominating point from \(E'\) with the one from the set \(E - E'\). The readers might have already noticed that \(|E'| \le |E|\).
%
\begin{algorithm}[bp]
\caption{Generate Pivot Points}
\label{algo:generate-pivot-points}
\begin{algorithmic}[1]
	\REQUIRE true PF extreme points $E^{\ast}$ from Algorithm \ref{algo:find-extreme-points}
	\STATE $E_c \leftarrow$ the extreme points from the current PF
	\STATE $E \leftarrow \{E^\ast \cup E_c\}$
	\STATE rank points in $E$, $E \rightarrow \{\mathcal{F}_1, \mathcal{F}_2, \ldots, \mathcal{F}_n\}$
	\STATE take the best front in $E'$, $E' \leftarrow \mathcal{F}_1$
	\FOR{all points $p_i$ in $E - E'$}
		\IF{$p_i$ weakly dominates any $p_j \in E'$}
			\STATE replace $p_j$ by $p_i$
		\ENDIF
	\ENDFOR
	\STATE update $E^\ast$, $E^\ast \leftarrow E'$
	\STATE $G \leftarrow$ find $k$ intermediary gap points from the current PF
	\STATE $E' \leftarrow \{E' \cup G\}$
	\RETURN $E'$
\end{algorithmic}
\end{algorithm}
%

% Figure
\begin{figure*}[!hbp]
	\centering
	\includegraphics[width=0.9\textwidth]{point-generation}
	\caption{The illustration of lines 9--12 in Algorithm \ref{algo:onsga2}. The right axes are the variable space and the left axes are the corresponding objective space. The point \(\mathbf{x_c}\) is the child (black circle) and \(\mathbf{x_p}\) is the parent (white circle). The point \(\mathbf{v}\) are the pivot points (grey circles). The operation will choose one of the directions denoted by \(L_1\), \(L_2\) or \(L_3\). If \(\mathbf{x_c}\) violates the variable bound then it is reverted back to the vicinity of the corresponding pivot point \(\mathbf{v}\).}
	\label{fig:opposite-creation}
\end{figure*}
%
Now, at this point, we can ensure that the set \(E'\) contains either true PF extremes or points near them. Now if we can generate new points near \(E'\), they will induce both better convergence and diversity. In section \ref{sec:limitation-canonical}, we have discussed a scenario where we can see how the bias in the search trajectory is introduced. However, the difference in the relative difficulty of the objective functions may not be the only reason for a bias. The imbalance in the solution distribution could happen for other reasons as well. For example, a disconnected Pareto-front, a local optimal front or a specific portion of the Pareto-front being more difficult to solve than the rest. In such cases, we can see a \textit{gap} forming over the Pareto-front during the search, we can see such a convergence pattern in many problems. As an example, we can see similar effect in solving ZDT4 problem as illustrated in Figure \ref{fig:zdt4-gap-snapshot}. To address these \textit{gaps}, we also find the solutions with \(k\)-highest (\(k = \) no. of objectives) crowding distance from the best front that are not \(\infty\), and call them as set \(G\). Clearly, the \(G\) solutions are those that reside on the edge of the broken front. Now we add the \(G\) to the set \(E'\), thus we make \(E'\) as the final ``pivot'' solutions to generate the opposite points. This should be also noted that \(|E'| > k\). This procedure is presented in Algorithm \ref{algo:generate-pivot-points}.
% Figure
\begin{figure}[tp]
	\centering
	\includegraphics[width=0.5\textwidth]{zdt4-gap}
	\caption{The effect of the \textit{gap} in the trade-off, could be seen when we try to solve ZDT4 problem with NSGA-II.}
	\label{fig:zdt4-gap-snapshot}
\end{figure}
%
%
\subsection{Integrating into an Elitist EMO Algorithm: NSGA-II}
\label{sec:onsga2r}
As we have mentioned at the beginning that we select front-wise best 25\% of the current population for opposite point generation. We go through each of them randomly and every time we pick \(k\) number of random points from \(E'\) and pick the pivot point that is the furthest from it, and find the opposite vector using a linear translation. A straight-forward way -- given a pivot vector \(\mathbf{v}\) and a parent vector \(\mathbf{x_p}\), we generate an opposite child \(\mathbf{x_c}\) as \(\mathbf{x_c} = \mathbf{x_p} + \mathbf{U}[(\frac{3d}{4}, \frac{5d}{4})] \circ (\frac{1}{d}(\mathbf{x_p} - \mathbf{v}))\). Here, \(d = ||\mathbf{v} - \mathbf{x_p}||\) and \(\mathbf{U}[(d,u)]\) is a uniform random vector where each element is within the range \([d,u]\). The overall procedure is presented in Algorithm \ref{algo:onsga2} in line 9--12 and illustrated in the Figure \ref{fig:opposite-creation}. The lines 9--12 in Algorithm \ref{algo:onsga2} can be recapped as follows: \(\mathbf{v}\) is on the true PF extreme and \(\mathbf{x_i}\) is \textit{far} from \(\mathbf{v}\), therefore, move \(\mathbf{x_i}\) closer to \(\mathbf{v}\) -- \textit{opposite} of \textit{far} is \textit{close}. Similar interpretation can be made when the vector \(\mathbf{v}\) is an intermediary \textit{gap}. 
%
\begin{algorithm}[tp]
\caption{NSGA-II with Opposition}
\label{algo:onsga2}
{\footnotesize
\begin{algorithmic}[1]
	\REQUIRE true PF extreme points $E^{\ast}$ from Algorithm \ref{algo:find-extreme-points}
	\STATE $N \leftarrow$ population size $|P_t|$
	\STATE $N_{\text{gen}} \leftarrow $ maximum generation
	\STATE $t \leftarrow 1$
	\WHILE{$t \le N_{\text{gen}}$}
		\STATE $P'_t \leftarrow$ select front-wise best 25\% solutions from $P_t$ and shuffle
		\STATE $E'_t \leftarrow$ construct pivot set $E'$ using algorithm \ref{algo:generate-pivot-points}
		\STATE $O_t \leftarrow \emptyset$
		\FOR{each solution $\mathbf{x_i} \in P'_t$}
			\STATE $S \leftarrow$ pick $k$ random solutions from $E'_t$
			\STATE $\mathbf{v} \leftarrow$ $\mathbf{v} \in S$ such that $\mathbf{v}$ is the furthest point from $\mathbf{x_i}$
			\STATE $d \leftarrow ||\mathbf{v} - \mathbf{x_i}||$
			\STATE $\mathbf{x_c} \leftarrow \mathbf{x_i} + \mathbf{U}[(\frac{3d}{4}, \frac{5d}{4})] \circ (\frac{1}{d}(\mathbf{x_i} - \mathbf{v}))$
			\STATE $x_j \leftarrow v_j \in \mathbf{v}$ if $x_j \in \mathbf{x_c} > x_{j_H}$ or $x_j \in \mathbf{x_c} < x_{j_L}$ 
			\STATE $O_t \leftarrow \{O_t \cup \mathbf{x_c}\}$
		\ENDFOR
		\STATE $P_t \leftarrow \{P_t \cup  E^\ast\}$
		\STATE $R_t \leftarrow \{P_t \cup Q_t\}$
		\STATE rank $R_t$ into fronts, $R_t \rightarrow \{\mathcal{F}_1, \mathcal{F}_2, \ldots, \mathcal{F}_n\}$
		\STATE $P_{t+1} \leftarrow \emptyset$
		\STATE $i \leftarrow 1$
		\WHILE{$|P_{t+1}| + |\mathcal{F}_i| \le N$}
			\STATE assign crowding distances on the front $\mathcal{F}_i$
			\STATE $P_{t+1} \leftarrow \{P_t \cup \mathcal{F}_i\}$
			\STATE $i \leftarrow i + 1$
		\ENDWHILE
		\STATE sort $\mathcal{F}_i$ in descending order using $\prec_n$
		\STATE $P_{t+1} \leftarrow$ the first $N - |P_{t+1}|$ solutions from $\mathcal{F}_i$
		\STATE $Q_{t+1} \leftarrow$ select, crossover and mutate $P_{t+1}$
		\STATE randomly insert all $x_i \in O_t$ into $Q_{t+1}$
		\STATE $t \leftarrow t + 1$
	\ENDWHILE
\end{algorithmic}}
\end{algorithm}
%
%
\begin{figure*}[bp!]
	\centering
	\subfloat[Convergence test for ZDT2 problem\label{subplot:zdt2-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt2-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for ZDT3 problem\label{subplot:zdt3-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-onsga2r-nsga2r-hvstat}}
	\hfill
	\subfloat[Convergence test for ZDT4 problem\label{subplot:zdt4-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt4-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for ZDT6 problem\label{subplot:zdt6-onsga2r}]{%
		\includegraphics[width=0.5\textwidth]{zdt6-onsga2r-nsga2r-hvstat}}
	\caption{These plots illustrates the comparative analysis of the convergence rates for different 2-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2r is NSGA-II.}
	\label{plot:onsga2r-hv-zdt}
\end{figure*}
%

Moreover, upon generating the vector \(\mathbf{x_c}\), it may happen that one of the variable values go beyond the variable bounds (i.e. \(x_j > x_{j_H}\) or \(x_j < x_{j_L}\)), in that case, we replace the overshot value from the corresponding variable value \(v_j\) from the pivot point \(\mathbf{v}\). Therefore, if a certain vector \(\mathbf{x_c}\) can't make a successful translation, then \(\mathbf{x_c}\) is reverted back to the vicinity of \(\mathbf{v}\). Thus, we assure a local best estimated translation of the parent vector \(\mathbf{x_p}\). This process is done on the line 13 of the Algorithm \ref{algo:onsga2}.

When we apply this algorithm to NSGA-II, we follow the obvious way, the generated opposite population will be inserted into the child population \(Q_t\), the Algorithm \ref{algo:onsga2} also shows how to integrate everything in NSGA-II. Moreover, this algorithm is ``pluggable'' in a sense that we can integrate it to any other elitist EMO algorithm. In the following section, we are going to see in details, how our opposite generation algorithm drastically improves the convergence rate.

% Figure
\begin{figure}[tp!]
	\centering
	\includegraphics[width=0.5\textwidth]{zdt1-onsga2r-nsga2r-hvstat}
	\caption{The convergence test of Algorithm \ref{algo:onsga2} (onsga2r) vs. NSGA-II on problem ZDT1}
	\label{plot:zdt1-onsga2r}
\end{figure}
%
%
\begin{figure*}[tp!]
	\centering
	\subfloat[Exploration at generation 3 -- ZDT3 problem\label{subfig:zdt3-gen-3}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-gen-3}}
	\subfloat[Exploration at generation 18 -- ZDT3 problem\label{subfig:zdt3-gen-18}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-gen-18}}
	\hfill
	\subfloat[Exploration at generation 27 -- ZDT3 problem\label{subfig:zdt3-gen-27}]{%
		\includegraphics[width=0.5\textwidth]{zdt3-gen-27}}
	\subfloat[Exploration at generation 21 -- ZDT4 problem\label{subfig:zdt4-gen-21}]{%
		\includegraphics[width=0.5\textwidth]{zdt4-gen-21}}
		\caption{This figure illustrates how our algorithm deterministically identifies which front needs to be explored first and gradually discovers the entire PF. The example here demonstrates a 3 cases of ZDT3 problem (Figure \ref{subfig:zdt3-gen-3}--\ref{subfig:zdt3-gen-27}). The outlier dots represents the deterministically generated solutions that did not survived because they are weakly dominated. The darks dots are those that are deterministically generated and survived. In the case of ZDT4 (Figure \ref{subfig:zdt4-gen-21}), we can see how the bias and gaps have been corrected by our approach.}
	\label{fig:zdt3-gap}
\end{figure*}
%
\section{Experiments with the Benchmark Problem Set}
\label{sec:onsga2r-zdt}
First we have tested the performance of Algorithm \ref{algo:onsga2} on \(5\) \(2\)-objective problems \cite{zdt-set}, namely ZDT1, ZDT2, ZDT3, ZDT4 and ZDT6, and we have set NSGA-II as the control. To maintain a fair comparison, we have compensated the extra function evaluations by the Algorithm \ref{algo:find-extreme-points} for the NSGA-II runs, and compared NSGA-II and Algorithm \ref{algo:onsga2} side by side. The performance measure for our test was Hypervolume (HV) \cite{wfg}, and we are interested to see which algorithm can reach to a desired HV within less function evaluations (FE). For all problems, we have seen our algorithm can demonstrate a very steep convergence to the true PF, even when the extra FE from Algorithm \ref{algo:find-extreme-points} are compensated for NSGA-II. 

All the results are collected from 31 independent runs started with non-identical random seeds. In all plots, \textit{onsga2r} stands for Algorithm \ref{algo:onsga2}. The extra cost to find the extreme points are indicated with a ``T'' arrow on the x-axis. During computation of the HV measure, we have set the reference point to \(\{2.0,2.0\}\) for all problems except ZDT6, where it has been set to \(\{4.0, 4.0\}\)\footnote{The code that we have used to compute HV measure was taken from \url{http://www.wfg.csse.uwa.edu.au/hypervolume/index.html#code}, where the implementation assumes that all the objective values need to be on the one side of the reference point. For ZDT6, a closer reference point made the curves in the plots to be showing up very late at the end of x-axis.}.

The experiment with ZDT1 is illustrated in Figure \ref{plot:zdt1-onsga2r}, here we can see that the Algorithm \ref{algo:find-extreme-points} takes up to around 2K of function evaluations. Given that, NSGA-II still lags behind with a multiple factors to reach the desired PF. We have seen similar effect on all the rest of the problems ZDT2, ZDT3, ZDT4 and ZDT6. Except for ZDT3, we can see some fluctuations due the disconnected nature of the true PF. All the plots for the rest of the problems are presented in Figure \ref{plot:onsga2r-hv-zdt}.

There is another interesting observation we have made, once this opposite point generation scheme is used, the search process becomes more focused and works in a more predictive manner. As an example, in the case of ZDT3 problem (where the true PF consists of 5 disconnected curves), the algorithm first tries to fill up the first partition and gradually moves to the next. The algorithm automatically detects which portion of the PF needs to be addressed first and try to fill the gaps by deliberately injecting points to the vicinity of those gaps. As a result our model can infer which objective is hard to solve and deterministically decides which one needs to be explored more. This scenario is illustrated in Figure \ref{fig:zdt3-gap}, where we can see how the point generation algorithm moves from one disconnected front to the next.

Moreover, our approach can also efficiently solve the issue of \textit{search trajectory bias}, if we look at the Figure \ref{subfig:zdt4-gen-21}, we can see that the new solutions are deterministically generated where the explorations are not done thoroughly yet.

%
\begin{figure*}[tp!]
	\centering
	\subfloat[Convergence test for DTLZ1 problem\label{subplot:dtlz1-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz1-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for DTLZ2 problem\label{subplot:dtlz2-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz2-onsga2r-nsga2r-hvstat}}
	\hfill
	\subfloat[Convergence test for DTLZ3 problem\label{subplot:dtlz3-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz3-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for DTLZ5 problem\label{subplot:dtlz5-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz5-onsga2r-nsga2r-hvstat}}
	\hfill
	\subfloat[Convergence test for DTLZ6 problem\label{subplot:dtlz6-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz6-onsga2r-nsga2r-hvstat}}
	\subfloat[Convergence test for DTLZ7 problem, our algorithm shows better performance in terms of mean and max hypervolume.\label{subplot:dtlz6-onsga2r}]{%
		\includegraphics[width=0.48\textwidth]{dtlz7-onsga2r-nsga2r-hvstat}}
	\caption{These plots illustrates the comparative analysis of the convergence rates for different 3-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2r is NSGA-II.}
	\label{plot:onsga2r-hv-dtlz}
\end{figure*}
%
\subsection{Experiments with the Scalable Problem Set}
\label{sec:onsga2r-dtlz}
In the next experiment, we have carried out the similar tests with the scalable problem sets -- DTLZ1, DTLZ2, DTLZ3, DTLZ4, DTLZ5, DTLZ6 and DTLZ7 \cite{dtlz-set}. For all cases we have considered \(3\)-objectives. The control was NSGA-II results and similarly we compensate the measure with the extra FE to find extremes. All the results are collated from 31 independent runs. The reference point for HV computation has been set to \(\{2.0, 2.0, 2.0\}\) for DTLZ2, DTLZ4 and DTLZ5. For DTLZ1 and DTLZ7 it has been set to \(\{10.0, 10.0, 10.0\}\), for DTLZ3 it was \(\{15.0, 15.0, 15.0\}\) and for DTLZ6, it was \(\{4.0, 4.0, 4.0\}\). All the convergence plots are presented in the Figure \ref{plot:onsga2r-hv-dtlz}. 

Here we can see, in DTLZ6 our approach shows noticeable improvement, and for DTLZ1, DTLZ3 and DTLZ7 the opposite point generation offers even greater improvement. However, for DTLZ2, DTLZ4 and DTLZ5 the opposition scheme does not offer any improvement. What we have seen for these problems, NSGA-II does not face much difficulties to reach to the true PF therefore the outcome stays same even if we introduce extreme points to guide the search. For example DTLZ6 is harder than DTLZ5\footnote{DTLZ5 and DTLZ6 are basically the same except an exponential growth added to the \(g\) function, and DTLZ7 has a disconnected PF.}, as a result, our approach shows even better efficacy in solving harder problems. There is another interesting fact that we need to acknowledge -- there is no way that our approach will degrade the performance of the host algorithm (i.e. NSGA-II), since all the points we generate are no worse than the existing solutions in the population. The opposition scheme invariably adds improvements on the convergence if there is any. 

%
\begin{figure*}[pb!]
	\centering
	\subfloat[ZDT4 problem\label{subplot:zdt4-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{zdt4-onsga2r-nsga2re-hvstat}}
	\subfloat[DTLZ3 problem\label{subplot:dtlz3-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{dtlz3-onsga2r-nsga2re-hvstat}}
	\hfill
	\subfloat[DTLZ6 problem\label{subplot:dtlz6-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{dtlz6-onsga2r-nsga2re-hvstat}}
	\subfloat[DTLZ7 problem\label{subplot:dtlz6-nsga2re}]{%
		\includegraphics[width=0.49\textwidth]{dtlz7-onsga2r-nsga2re-hvstat}}
		\caption{These plots illustrates the comparative analysis of the convergence rates for different 2 and 3-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2re is the NSGA-II equipped with extreme points.}
	\label{plot:nsga2re-hv}
\end{figure*}
%
% Figure
\begin{figure}[!tp]
	\centering
	\includegraphics[width=0.5\textwidth]{dtlz4-longvar}
	\caption{The experiment with the varying variable length for DTLZ4 problem. `onsga2r' stands for our approach and `nsga2r' is the NSGA-II algorithm, \(n\) is the variable size. NSGA-II is also compensated for the extra function evaluations to find the true PF extremes. The lines for our algorithm shows the \textit{minimum} hypervolume achieved in each run; and for NSGA-II, we have taken the \textit{maximum} of it.}
	\label{plot:longvar}\vspace{-10.0pt}
\end{figure}
%
\subsection{Expanding the Search Space} 
\label{subsec:longvar}
For DTLZ2, DTLZ4 and DTLZ5 problems, we have already seen that the convergence gain was not noticeable. However, still we are not clear how our model will behave if the problem difficulty is increased. To investigate, we have increased the number of variables \(n\) to see if we can improve. For example we have picked one problem like DTLZ4 and did the same experiments with varying number of design variables. The standard setting for DTLZ4 is \(n = 12\), we have changed this length from \(12\) to \(60\) and \(96\). The outcome of this test is quite interesting -- the applicability of our approach is increased with the number of variables, and this effect is identical for DTLZ2 and DTLZ5 as well. This result for DTLZ4 is presented in the Figure \ref{plot:longvar}, here we can see at \(n = 96\), our approach shows the most gain in the convergence speed-up, and if we make \(n\) even bigger, the trend becomes more conspicuous. Moreover, in Figure \ref{plot:longvar}, we have shown \textit{minimum} hypervolume achieved with our approach and the \textit{maximum} possible hypervolume achieved by the NSGA-II algorithm.

For this experiment, we did not use MADS algorithm to find the extreme solutions, although these problems have local optima. The MADS algorithm is good for finding more accurate extreme points for small problems with local optima -- with smaller function evaluations, however, the performance of MADS degrades as the number of variables gets bigger, where a budgeted evaluation is a requirement. Our empirical investigation shows that for large variable space, IP methods give reasonably close (at least that are good for our purpose) extreme points within the acceptable function evaluations.

%
\begin{figure*}[!htp]
	\centering
	\subfloat[ZDT4 problem\label{subplot:zdt4-weak}]{%
		\includegraphics[width=0.49\textwidth]{zdt4-weak}}
	\subfloat[DTLZ1 problem\label{subplot:dtlz1-weak}]{%
		\includegraphics[width=0.49\textwidth]{dtlz1-weak}}
	\hfill
	\caption{These plots illustrates the comparative analysis of the convergence rates for 2 and 3-objective problems, the curves are actually consisted of box-plots. Here onsga2r denotes our algorithm and nsga2r is the NSGA-II. Here the Algorithm \ref{algo:onsga2} starts with deliberately injected weakly dominated extreme solutions. For ZDT4 it has been set to \(\{(1.0, 41.0), (0.0, 68.0)\}\) and for DTLZ1 it was \(\{(0.0, 217.5, 13.7),(67.6, 0.48, 0.0),(0.0, 0.0, 32.0)\}\).}
	\label{plot:weak-hv}
\end{figure*}
%
\subsection{Next Experiment: NSGA-II Equipped with Extreme Points}
\label{subsec:nsga2re}
We were also very curious to see, what if we introduce the extreme points to the NSGA-II so that it can utilize them to converge to the true PF. In this case, we compute the pivot points from the initial population, inject them and let the NSGA-II run. Here NSGA-II does not employ any opposite point generation scheme. All the test parameters were kept same as before and the results are summarized in the Figure \ref{plot:nsga2re-hv}. Here, we can see that the convergence rate is still noticeably improved, but NSGA-II with extreme points shows a noticeable variance during the convergence and our approach is more robust (i.e. shows less variance). This is because our approach generate new points in a very deterministic and predictable manner and the NSGA-II tries to emulate this by applying mutation/crossover. We also need to remember that we set aside only 25\% of the original population to be subjected to opposition. We only add a subset of our original results in the Figure \ref{plot:nsga2re-hv}, since all of them shows the similar trend as in Figure \ref{plot:onsga2r-hv-zdt} and \ref{plot:onsga2r-hv-dtlz}.

In the next sections we are going to experiments with more interesting what-if analysis -- how does our model perform what if the true PF extremes are not found, how does the deterministically generated points (i.e. opposite solutions) contribute to the search mechanism etc.

\subsection{Experiment with The Weakly Dominated Extreme Points}
\label{sec:weak-extremes}
In this paper, all the experiments were carried out on the standard benchmark problems popular among the EMO practitioners, however in other situation, it may be very hard to find the true PF extremes. In this experiment we will try to address this issue by deliberately setting the extreme points as weakly dominated solutions of varying distances from the true PF extremes. More specifically, for ZDT1 problem, the true PF extremes are located at \(\{(1.0, 0.0, (0.0, 1.0)\}\), but we will start the algorithm with \(\{(2.0, 0.0), (0.0, 2.0)\}\), \(\{(4.0, 0.0), (0.0, 4.0)\}\) etc. and see if we can still keep the performance (or if degrades, how do they degrade).

The results are shown for problems ZDT4 and DTLZ1 in Figure \ref{plot:weak-hv}, here we can see that for ZDT4 problem our approach runs with more variance however, the mean/median hypervolume values are still better than the NSGA-II runs. For DTLZ1, interestingly our approach shows steep rise in the convergence rate. However, in both cases, the cost of finding the weakly extreme points is not compensated, therefore both algorithms start with the same point on the x-axis. Even if such compensation were made, still our approach is better off than the NSGA-II for DTLZ1, but in the case for ZDT4, the trends will going to  be more overlapped. However, if we consider the mean/median HV measure, our approach still offers a better convergence speed and the similar trend has been noticed for all other problems. This experiment confirms that our approach is still viable even if the extreme points are \textit{very} far from the true PF-extremes.

%
\begin{figure*}[!hbp]
	\centering
	\subfloat[ZDT4 problem\label{subplot:zdt4-hv-trend}]{%
		\includegraphics[width=0.49\textwidth]{zdt4-hv-trend}}
	\subfloat[DTLZ3 problem\label{subplot:dtlz3-hv-trend}]{%
		\includegraphics[width=0.49\textwidth]{dtlz3-hv-trend}}
	\hfill
	\caption{These plots illustrates the comparative analysis of the mean-HV convergence rates for 2 and 3-objective problems, with varying rates for opposite point allocation ratio. For DTLZ3, we can see that the allocation ratio of \(90\%\) makes the most negative effect on the convergence rate.}
	\label{plot:hv-trends}
\end{figure*}
%
\section{Analysis of The Opposite Solution Survival Rates}
\label{sec:survival}
In the next part, we will see how the deterministically generated solutions survives the selection mechanism at the line 28 in Algorithm \ref{algo:onsga2}. To do this we assign flags to the generated opposite solutions in every generation and count how many of them are passing through the selection phase. Interestingly, in all of the cases, this survival rate is very high during the initial generations and steeply settles down to \(\sim30\%\). This was really confounding to notice why this rate almost always settles down to a specific number, especially in those cases when the opposition approach shows a better convergence pay-offs. This scenario is presented in the Figure \ref{plot:zdt1-survival}, where the highest survival rate (\(88\%\)) has been achieved at generation \(2\) and reached the equilibrium at \(33\%\). In order to make this illustrations more compact, we present these statistics in the Table \ref{table:survival}.

%
\begin{table*}[tp!]
	\caption{Mean Static Survival Rates for Different Problems}
	\label{table:survival}
	\centering
	{\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{l|llllllll|llll}
	Problems		& ZDT1 & ZDT2 & ZDT4 & ZDT6 & DTLZ1 & DTLZ3 & DTLZ6 & DTLZ7 & ZDT3 & DTLZ2 & DTLZ4 & DTLZ5\\ \hline
	$\textit{Speed-up}(A,B)$	& \textbf{2.67} & \textbf{3.56} & \textbf{2.93} & \textbf{6.82} & \textbf{2.14} & \textbf{2.59} & \textbf{1.22} & \textbf{2.47} & 0.0 & 0.0 & 0.0 & 0.0\\ \hline
	Static Survival Rate (\(\%\))	& \textbf{33.0} & \textbf{32.6}	& \textbf{26.0} & \textbf{28.5} & \textbf{27.4} & 22.2 & 11.8 & \textbf{28.8} & 19.1 & 24.7 & 19.0 & \textbf{29.6}\\ \hline
	\end{tabular}}
\end{table*}
%
% Figure
\begin{figure}[tp]
	\centering
	\includegraphics[width=0.5\textwidth]{zdt1-onsga2r-survival}
	\caption{The survival rate problem ZDT1 over the generations, we can see the highest peek at generation \(2\) and settles down to \(33\%\) around generation \(60\).}
	\label{plot:zdt1-survival}
\end{figure}
%
Please also note that all the experiment data were collated from \(31\) independent runs, therefore the survival rate is calculated as the mean of those \(31\) runs at each generation. For a better quantification of this statistics, we have measured the \textit{Speed-up} ratio of a pair algorithms (Algorithm-\(A\), algorithm-\(B\)) in the most obvious way --
%
\begin{equation}
	\textit{Speed-up}(A,B) = \frac{\text{FE}_A \ge r \overline{\text{HV}}_{B_{\text{max}}}}{\text{FE}_B = \overline{\text{HV}}_{B_{\text{max}}}}
	\label{eq:speed-up}
\end{equation}
%
Here, \(\text{FE}_A\) and \(\text{FE}_B\) denotes the function evaluation for Algorithm-\(A\) and \(B\) respectively. \(\overline{\text{HV}}_{B_{\text{max}}}\) denotes the maxmium mean-HV measure for the Algorithm-\(B\) in the convergence plot; and \(r\) is a value \(0.0 < r \le 1.0\). Hence, the above expression computes the ratio of the function evaluation of \(A\) to reach \textit{at-least} a certain \(r\)-portion of the maximum of the mean-hypervolumes of \(B\) and the function evaluation of \(B\) to reach its maximum of the mean-hypervolumes. 

Therefore, if the Algorithm-\(A\) has a slower convergence rate than that of Algorithm-\(B\), then \(\textit{Speed-up}(A,B) > 0.0\), otherwise it will be equal to 0.0. For all the cases, we have set the value of \(r\) within \(0.8 \le r \le 0.9\) -- every time we chose the value of \(r\) depending on how much accurate we want to capture the speed-ups from the convergence plots. For example, in the Table \ref{table:survival}, the Algorithm-\(A\) is NSGA-II and \(B\) is our approach. Any \textit{Speed-up} value greater than 1.0 means our approach has a better convergence rate than that of NSGA-II.

%
\begin{figure*}[!htp]
	\centering
	\subfloat[ZDT4 problem\label{subplot:zdt4-survival-trend}]{%
		\includegraphics[width=0.49\textwidth]{zdt4-survival-trend}}
	\subfloat[DTLZ3 problem\label{subplot:dtlz3-survival-trend}]{%
		\includegraphics[width=0.49\textwidth]{dtlz3-survival-trend}}
	\hfill
	\caption{These plots illustrates the mean-static survival-rates for 2 and 3-objective problems, with varying rates for opposite point allocation ratio. In both cases we can see that the rate of survival decreases with increase in the allocation ratio.}
	\label{plot:survival-trends}
\end{figure*}
%
%
\begin{figure*}[!hbp]
	\centering
	\subfloat[at generation 6, hitting the true PF\label{subplot:zdt4-hns-gen-6}]{%
		\includegraphics[width=0.34\textwidth]{zdt4-hns-gen-6}}
	\subfloat[at generation 15, spreading upward\label{subplot:zdt4-hns-gen-15}]{%
		\includegraphics[width=0.34\textwidth]{zdt4-hns-gen-15}}
	\subfloat[at generation 36, spreading downward\label{subplot:zdt4-hns-gen-36}]{%
		\includegraphics[width=0.34\textwidth]{zdt4-hns-gen-36}}
	\hfill
	\caption{This figure illustrates the ``hit-and-spread'' nature of the single pivot point case. This plot demonstrated a scenario for ZDT4 problem, here we can clearly see trajectory of the optimization procedure.}
	\label{plot:hit-n-spread}
\end{figure*}
%
\subsection{Varying The Opposite Solution Allocation Ratio}
\label{subsec:op-ratio}
However, the above statistics neither says much about why there have always been a static ratio of survival rates nor it will be a constant if we change the number of allocated solution for opposition. In all of our experiments, this allocation has been set to \(25\%\), therefore, if the population size is \(100\) and if the survival rate is \(30\%\), then around only \(25 \times 0.3 = 7.5 \sim 8\) solutions help to achieve such convergence gain. Now we want to see, if it is possible to improve the convergence by increasing the opposite solution allocation ratio from \(25\%\). However, it turns out be a discouraging attempt, when we increase this allocation rate, the survival rate also decreases accordingly. Even for some problems, a smaller allocation ratio has been found to be more effective. This statistics has been presented in Figure \ref{plot:hv-trends} and \ref{plot:survival-trends}, where for each cases, the allocation ratio has been changed from \(10\%\) to \(90\%\).

Interestingly, for DTLZ3 if the opposite solution allocation ratio is \(10\%\), it shows the best \textit{Speed-up}, then it degrades as the allocation ratio has been increased. But for ZDT4, the variance is not much noticeable. However, in general, we have seen that a smaller opposite allocation ratio tends to show better convergence speed.\vfill \eject

%
\begin{figure*}[!htp]
	\centering
	\subfloat[DTLZ3 problem\label{subplot:dtlz3-single-pf}]{%
		\includegraphics[width=0.49\textwidth]{dtlz3-onsga2r-onsga2rw-hvstat}}
	\subfloat[DTLZ6 problem\label{subplot:dtlz6-single-pf}]{%
		\includegraphics[width=0.49\textwidth]{dtlz6-onsga2r-onsga2rw-hvstat}}
	\hfill
	\caption{Similar convergence plots for the algorithm with single intermediary pivot point. Here we can see a noticeable improvement on the DTLZ3 problem.}
	\label{plot:single-pf}
\end{figure*}
%
%
% \begin{figure*}[!htb]
% 	\centering
% 	\subfloat[ZDT4 problem -- the \textit{inverse-opposite} is slightly better\label{subplot:zdt4-hv-opschemes}]{%
% 		\includegraphics[width=0.49\textwidth]{zdt4-hv-opschemes}}
% 	\subfloat[ZDT6 problem -- the \textit{random} is slightly better\label{subplot:zdt6-hv-opschemes}]{%
% 		\includegraphics[width=0.49\textwidth]{zdt6-hv-opschemes}}
% 	\hfill
% 	\caption{The mean-HV convergence plots for the algorithm with inverse notion of \textit{opposition} used in the original algorithm. Here we can see there is not much change in the convergence rates. The black line is from the mean-HV values of the original \textit{opposition} based algorithm, the grey line is found from the \textit{inverse-opposition} based pivot selection scheme and the light line corresponds to a \textit{random} pivot selection scheme.}
% 	\label{plot:opschemes}
% \end{figure*}
%
\section{Applying Opposition Over A Single True-PF Solution}
\label{sec:single-pf}
So far, our focus was to create the complete PF from limited information -- namely using \(k\)-number of true-PF extremes. However, this approach also comes with some limitations. For example, in many hard problems, where there are lots of local optima, it is sometimes hard to exactly pin-point the true-PF extremes. For 3-objective problems, it is also sometimes hard to find all the true-PF extremes and we end up locating only a subset of them or some weakly dominated extreme points. Moreover, as we are allocating a fixed budget for finding the true extremes, the allocation of function evaluation for each objective decreases as the number of objectives become larger. Therefore, this approach may not be much useful if we want to solve a \textit{many-objective} problem.

In such cases, finding \(k\)-number of true-PF extremes might not be a practical way, therefore we need to come-up with a more streamlined approach to tackle this problem. In this experiment, we will try to see what if we provide only \textit{one} intermediary (non-extreme) true-PF solution to our algorithm. In this case, we are concerned with finding only \textit{one} (and \textit{any}) point on the true-PF, thus drastically reducing the computational cost associated with gleaning the ``limited'' information. To do this, we follow a similar (yet even more simple) approach as presented in the Algorithm \ref{algo:find-extreme-points}. In this case, in stead of considering each objective separately, we will solve a weighted sum of all the objectives -- during the first \(\frac{T}{2}\)-budget, we will optimize the function in the form of \(f_w(\mathbf{x}) = \sum_{j=1}^k w_j f_j(\mathbf{x})\), where \(w_j = \frac{1}{k}\). Obviously, for the AASF part, we will use the same function except taking the weights as \(w_j = \frac{1}{k}\). Therefore, now the loop in the line 6 in Algorithm \ref{algo:find-extreme-points} can be disregarded and the total budget is now basically \(\frac{1}{k}\)-th of the previous cost.

Now, at the beginning, the set \(E^\ast\) in the Algorithm \ref{algo:generate-pivot-points} will contain only 1 point (instead of \(k\)) and the rest of the routines have been kept as same as before for both Algorithm \ref{algo:generate-pivot-points} and \ref{algo:onsga2}. In the Algorithm \ref{algo:onsga2}, the procedure will now start to optimize by accumulating solutions near one pivot point and gradually try to explore by finding new extremes from that point. In fact, now the algorithm behaves like in a ``hit-and-spread'' manner -- first it will try to hit the true-PF on the vicinity of the pivot solution and gradually, once it starts to getting the extremes, the algorithm will try to populate the set \(E_c\), \(G\) and \(E\) in the same manner. This mechanism is illustrated in the Figure \ref{plot:hit-n-spread}, where we can see how the algorithm first hits the pivot point on the true-PF and then it starts to spread left and right over the true Pareto-front.

Interestingly, this approach shows a noticeable improvement over the original algorithm for a certain problems -- especially in DTLZ3 and DTLZ6. For the rest of the problems we could not find much difference but slightly better in some other cases. The convergence plots for this approach on the problem DTLZ3 and DTLZ6 are presented in the Figure \ref{plot:single-pf}. Here we can see, for DTLZ3 the improvement is even better. However, there is one limitation that we need to acknowledge for this approach, if the true-PF is disconnected then it will be very difficult to locate an intermediary pivot point since there is no way to infer the \(w_j\) values that will ensure a valid point on the true-PF, the same argument applied when the problem is constrained.

\begin{comment}
\section{Disregarding The Notion of Opposition}
\label{sec:inv-opp}
The central part of our study is the meaningful integration of the notion of \textit{opposition} in EMO algorithms. Therefore, we have adopted the semantics of opposition as \textit{far-vs-close} and \textit{crowded-vs-isolated} etc., and to precisely implement it, we are choosing the pivot points \(\mathbf{v}\) that is the \textit{farthest} from current parent \(\mathbf{x_p}\). Now, one can ask, what if we do not do it in this way, what if we choose the \textit{closest} pivot from the parent instead of the \textit{farthest} pivot ? More specifically, our concern is if \textit{the notion of opposition} being really helpful or not.

To address this query, we have changed the line 10 of the Algorithm \ref{algo:onsga2} to pick the \textit{closest} point \(\mathbf{v}\) instead of the \textit{farthest} one. We have also tested with a version where we pick the pivot point in random -- completely disregarding any distance measure from the parent solution. Such a setup now comes with a very interesting result -- it turns out that the semantics of \textit{far-vs-close} is not that important at all. However, for the purpose of the \text{gap}-filling, the property of \textit{crowded-vs-isolated} is important. This experiment is presented in the Figure \ref{plot:opschemes}, where the results are presented for ZDT4 and ZDT6 problems. We can see that whatever method we use to pick the pivot point (i.e. random or inverse-opposite), the overall convergence changes are very negligible. Because, whatever point \(\mathbf{v}\) we choose, if we can generate \textit{any} solution near it, it will always be useful (i.e. non-dominated). So, the gain of the convergence speed actually does not come from the state of being close (or far) from the true-PF -- wherever we are, if we can generate \textit{any} point near \textit{any} pivot, we can win the convergence race.

Interestingly, this observation once-again confirms the notion of the \textit{generality} in the trade-off solutions, upon which the concept of so-called ``innovization'' \cite{innovization} depends. The ``innovization'' principle deals with finding the most \textit{general} properties from the solutions on the true-PF, and such properties are again utilized to construct better designs. In this case, our solution generation scheme inadvertently uses this principle to generate non-dominated solutions. For example, in the case of ZDT4 problem, the total number of variable is 10; among them, the first variable dictates the trade-off on the Pareto-front, all the solutions on the true-PF has same variable values from variable 2 to 10 which is a solution to Rastrigin's problem. Therefore, if we can locate at least one solution on the true-PF, any solution on its vicinity will share the similar variable values that is the solution to Rastrigin's problem. By following the same argument, we can assume that if we perturb the pivot solution on the true-PF, we supposed to get other non-dominated solutions, however such technique has been already discussed in the sub-section \ref{subsec:nsga2re}, and we have seen that such approach does not work well. Therefore, our approach offers an informative and a deterministic way to utilize this \textit{Pareto-set generality} to generate other solutions on the true-PF.
\end{comment}

\section{Computation Cost}
\label{sec:big-o}
The principal overhead for our approach is the complexity incurred by the Algorithm \ref{algo:find-extreme-points}, where the computational cost comes from the IP and the MADS algorithm. However, this IP or MADS function call is a one-pass process. Therefore, we are going to see the how the rest of the algorithm imposes the extra computational overhead on the host algorithm (i.e. NSGA-II). The line 6 in Algorithm \ref{algo:onsga2} is a call to Algorithm \ref{algo:generate-pivot-points}. The expensive part of this algorithm is line 11 -- which is in fact, a linear function of \(N\) (\(N = \text{population size}\)), i.e. \(\Theta(N)\) and all the other terms are function of \(k\) (\(k = \text{no. of objectives}\)). Therefore the overall complexity for the Algorithm \ref{algo:generate-pivot-points} is \(O(N)\). The loop 8--14 takes exactly \(\Theta(\frac{N}{4}) < O(N)\), the same goes with line 29. Therefore, our approach does not add any extra computational cost to NSGA-II algorithm.

\section{Conclusions and Future Works}
\label{sec:conclusion}
The main contribution of this paper is the incorporation of opposite point generation scheme in a different perspective. We have shown that the notion of \textit{opposition} can be utilized in a different ways. Our approach also shows that a simple and a deterministic scheme can aid the EMO optimization algorithm in a very interesting way. Our technique is also easy to implement and offers less overhead to the host algorithm. This approach can also correct the search bias introduced by the problem difficulty in an automated and predictable manner. We have also seen that the efficacy of our algorithm becomes more salient with the increasing level of problem difficulty. Even though we have carried out a quite extensive study of our model on a variety of benchmark problems, but we did not do any study on real world problems. The original idea of the \textit{Opposition Based Learning (OBL)} is quite interesting; and we can make more of it if this idea is utilized in a more meaningful way -- we think this is the main contribution of our study.  

However, in the future we want to address some other interesting issues with our current study, especially in the ``many-objective'' problems. As we have seen, our approach spends a good portion of the function evaluations to compute the extreme points for each objective separately. This overhead becomes more of a problem when the number of objective is multiplied. In such case, our current model might not be much useful. Moreover, finding the extreme points itself comes with its own set of problems -- i)finding the accurate extreme points are not guaranteed ii)the identification of extremes becomes more problematic when the true PF is a disconnected front iii) notionally, the extreme points are harder to find than any other non-extreme points on the true PF as ``being extreme'' could be interpreted as another constraint. Therefore, the integral dependency on the extreme points -- we think a limitation of our approach.

In the future work, we are going to address these issues. Moreover, we think there are also a possible scope in changing the idea \textit{opposition} for reference point based many-objective algorithms like MOEA/D and NSGA-III \cite{nsga3-main-p1}\cite{nsga3-main-p2}. In the future research, we hope to investigate these ideas.

\begin{comment}
\section{The {\secit Body} of The Paper}
Typically, the body of a paper is organized
into a hierarchical structure, with numbered or unnumbered
headings for sections, subsections, sub-subsections, and even
smaller sections.  The command \texttt{{\char'134}section} that
precedes this paragraph is part of such a
hierarchy.\footnote{This is the second footnote.  It
starts a series of three footnotes that add nothing
informational, but just give an idea of how footnotes work
and look. It is a wordy one, just so you see
how a longish one plays out.} \LaTeX\ handles the numbering
and placement of these headings for you, when you use
the appropriate heading commands around the titles
of the headings.  If you want a sub-subsection or
smaller part to be unnumbered in your output, simply append an
asterisk to the command name.  Examples of both
numbered and unnumbered headings will appear throughout the
balance of this sample document.

Because the entire article is contained in
the \textbf{document} environment, you can indicate the
start of a new paragraph with a blank line in your
input file; that is why this sentence forms a separate paragraph.

\subsection{Type Changes and {\subsecit Special} Characters}
We have already seen several typeface changes in this sample.  You
can indicate italicized words or phrases in your text with
the command \texttt{{\char'134}textit}; emboldening with the
command \texttt{{\char'134}textbf}
and typewriter-style (for instance, for computer code) with
\texttt{{\char'134}texttt}.  But remember, you do not
have to indicate typestyle changes when such changes are
part of the \textit{structural} elements of your
article; for instance, the heading of this subsection will
be in a sans serif\footnote{A third footnote, here.
Let's make this a rather short one to
see how it looks.} typeface, but that is handled by the
document class file. Take care with the use
of\footnote{A fourth, and last, footnote.}
the curly braces in typeface changes; they mark
the beginning and end of
the text that is to be in the different typeface.

You can use whatever symbols, accented characters, or
non-English characters you need anywhere in your document;
you can find a complete list of what is
available in the \textit{\LaTeX\
User's Guide}\cite{Lamport:LaTeX}.

\subsection{Math Equations}
You may want to display math equations in three distinct styles:
inline, numbered or non-numbered display.  Each of
the three are discussed in the next sections.

\subsubsection{Inline (In-text) Equations}
A formula that appears in the running text is called an
inline or in-text formula.  It is produced by the
\textbf{math} environment, which can be
invoked with the usual \texttt{{\char'134}begin. . .{\char'134}end}
construction or with the short form \texttt{\$. . .\$}. You
can use any of the symbols and structures,
from $\alpha$ to $\omega$, available in
\LaTeX\cite{Lamport:LaTeX}; this section will simply show a
few examples of in-text equations in context. Notice how
this equation: \begin{math}\lim_{n\rightarrow \infty}x=0\end{math},
set here in in-line math style, looks slightly different when
set in display style.  (See next section).

\subsubsection{Display Equations}
A numbered display equation -- one set off by vertical space
from the text and centered horizontally -- is produced
by the \textbf{equation} environment. An unnumbered display
equation is produced by the \textbf{displaymath} environment.

Again, in either environment, you can use any of the symbols
and structures available in \LaTeX; this section will just
give a couple of examples of display equations in context.
First, consider the equation, shown as an inline equation above:
\begin{equation}\lim_{n\rightarrow \infty}x=0\end{equation}
Notice how it is formatted somewhat differently in
the \textbf{displaymath}
environment.  Now, we'll enter an unnumbered equation:
\begin{displaymath}\sum_{i=0}^{\infty} x + 1\end{displaymath}
and follow it with another numbered equation:
\begin{equation}\sum_{i=0}^{\infty}x_i=\int_{0}^{\pi+2} f\end{equation}
just to demonstrate \LaTeX's able handling of numbering.

\subsection{Citations}
Citations to articles \cite{bowman:reasoning,
clark:pct, braams:babel, herlihy:methodology},
conference proceedings \cite{clark:pct} or
books \cite{salas:calculus, Lamport:LaTeX} listed
in the Bibliography section of your
article will occur throughout the text of your article.
You should use BibTeX to automatically produce this bibliography;
you simply need to insert one of several citation commands with
a key of the item cited in the proper location in
the \texttt{.tex} file \cite{Lamport:LaTeX}.
The key is a short reference you invent to uniquely
identify each work; in this sample document, the key is
the first author's surname and a
word from the title.  This identifying key is included
with each item in the \texttt{.bib} file for your article.

The details of the construction of the \texttt{.bib} file
are beyond the scope of this sample document, but more
information can be found in the \textit{Author's Guide},
and exhaustive details in the \textit{\LaTeX\ User's
Guide}\cite{Lamport:LaTeX}.

This article shows only the plainest form
of the citation command, using \texttt{{\char'134}cite}.
This is what is stipulated in the SIGS style specifications.
No other citation format is endorsed or supported.

\subsection{Tables}
Because tables cannot be split across pages, the best
placement for them is typically the top of the page
nearest their initial cite.  To
ensure this proper ``floating'' placement of tables, use the
environment \textbf{table} to enclose the table's contents and
the table caption.  The contents of the table itself must go
in the \textbf{tabular} environment, to
be aligned properly in rows and columns, with the desired
horizontal and vertical rules.  Again, detailed instructions
on \textbf{tabular} material
is found in the \textit{\LaTeX\ User's Guide}.

Immediately following this sentence is the point at which
Table 1 is included in the input file; compare the
placement of the table here with the table in the printed
dvi output of this document.

\begin{table}
\centering
\caption{Frequency of Special Characters}
\begin{tabular}{|c|c|l|} \hline
Non-English or Math&Frequency&Comments\\ \hline
\O & 1 in 1,000& For Swedish names\\ \hline
$\pi$ & 1 in 5& Common in math\\ \hline
\$ & 4 in 5 & Used in business\\ \hline
$\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
\hline\end{tabular}
\end{table}

To set a wider table, which takes up the whole width of
the page's live area, use the environment
\textbf{table*} to enclose the table's contents and
the table caption.  As with a single-column table, this wide
table will ``float" to a location deemed more desirable.
Immediately following this sentence is the point at which
Table 2 is included in the input file; again, it is
instructive to compare the placement of the
table here with the table in the printed dvi
output of this document.


\begin{table*}
\centering
\caption{Some Typical Commands}
\begin{tabular}{|c|c|l|} \hline
Command&A Number&Comments\\ \hline
\texttt{{\char'134}alignauthor} & 100& Author alignment\\ \hline
\texttt{{\char'134}numberofauthors}& 200& Author enumeration\\ \hline
\texttt{{\char'134}table}& 300 & For tables\\ \hline
\texttt{{\char'134}table*}& 400& For wider tables\\ \hline\end{tabular}
\end{table*}
% end the environment with {table*}, NOTE not {table}!

\subsection{Figures}
Like tables, figures cannot be split across pages; the
best placement for them
is typically the top or the bottom of the page nearest
their initial cite.  To ensure this proper ``floating'' placement
of figures, use the environment
\textbf{figure} to enclose the figure and its caption.

This sample document contains examples of \textbf{.eps} files to be
displayable with \LaTeX.  If you work with pdf\LaTeX, use files in the
\textbf{.pdf} format.  Note that most modern \TeX\ system will convert
\textbf{.eps} to \textbf{.pdf} for you on the fly.  More details on
each of these is found in the \textit{Author's Guide}.

\begin{figure}
\centering
\includegraphics{fly}
\caption{A sample black and white graphic.}
\end{figure}

\begin{figure}
\centering
\includegraphics[height=1in, width=1in]{fly}
\caption{A sample black and white graphic
that has been resized with the \texttt{includegraphics} command.}
\end{figure}


As was the case with tables, you may want a figure
that spans two columns.  To do this, and still to
ensure proper ``floating'' placement of tables, use the environment
\textbf{figure*} to enclose the figure and its caption.
and don't forget to end the environment with
{figure*}, not {figure}!

\begin{figure*}
\centering
\includegraphics{flies}
\caption{A sample black and white graphic
that needs to span two columns of text.}
\end{figure*}


\begin{figure}
\centering
\includegraphics[height=1in, width=1in]{rosette}
\caption{A sample black and white graphic that has
been resized with the \texttt{includegraphics} command.}
\vskip -6pt
\end{figure}

\subsection{Theorem-like Constructs}
Other common constructs that may occur in your article are
the forms for logical constructs like theorems, axioms,
corollaries and proofs.  There are
two forms, one produced by the
command \texttt{{\char'134}newtheorem} and the
other by the command \texttt{{\char'134}newdef}; perhaps
the clearest and easiest way to distinguish them is
to compare the two in the output of this sample document:

This uses the \textbf{theorem} environment, created by
the\linebreak\texttt{{\char'134}newtheorem} command:
\newtheorem{theorem}{Theorem}
\begin{theorem}
Let $f$ be continuous on $[a,b]$.  If $G$ is
an antiderivative for $f$ on $[a,b]$, then
\begin{displaymath}\int^b_af(t)dt = G(b) - G(a).\end{displaymath}
\end{theorem}

The other uses the \textbf{definition} environment, created
by the \texttt{{\char'134}newdef} command:
\newdef{definition}{Definition}
\begin{definition}
If $z$ is irrational, then by $e^z$ we mean the
unique number which has
logarithm $z$: \begin{displaymath}{\log e^z = z}\end{displaymath}
\end{definition}

Two lists of constructs that use one of these
forms is given in the
\textit{Author's  Guidelines}.
 
There is one other similar construct environment, which is
already set up
for you; i.e. you must \textit{not} use
a \texttt{{\char'134}newdef} command to
create it: the \textbf{proof} environment.  Here
is a example of its use:
\begin{proof}
Suppose on the contrary there exists a real number $L$ such that
\begin{displaymath}
\lim_{x\rightarrow\infty} \frac{f(x)}{g(x)} = L.
\end{displaymath}
Then
\begin{displaymath}
l=\lim_{x\rightarrow c} f(x)
= \lim_{x\rightarrow c}
\left[ g{x} \cdot \frac{f(x)}{g(x)} \right ]
= \lim_{x\rightarrow c} g(x) \cdot \lim_{x\rightarrow c}
\frac{f(x)}{g(x)} = 0\cdot L = 0,
\end{displaymath}
which contradicts our assumption that $l\neq 0$.
\end{proof}

Complete rules about using these environments and using the
two different creation commands are in the
\textit{Author's Guide}; please consult it for more
detailed instructions.  If you need to use another construct,
not listed therein, which you want to have the same
formatting as the Theorem
or the Definition\cite{salas:calculus} shown above,
use the \texttt{{\char'134}newtheorem} or the
\texttt{{\char'134}newdef} command,
respectively, to create it.

\subsection*{A {\secit Caveat} for the \TeX\ Expert}
Because you have just been given permission to
use the \texttt{{\char'134}newdef} command to create a
new form, you might think you can
use \TeX's \texttt{{\char'134}def} to create a
new command: \textit{Please refrain from doing this!}
Remember that your \LaTeX\ source code is primarily intended
to create camera-ready copy, but may be converted
to other forms -- e.g. HTML. If you inadvertently omit
some or all of the \texttt{{\char'134}def}s recompilation will
be, to say the least, problematic.

\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate

\end{comment}
%ACKNOWLEDGMENTS are optional
\section{Acknowledgments}
This section is optional; it is a location for you
to acknowledge grants, funding, editing assistance and
what have you.  In the present case, for example, the
authors would like to thank Gerald Murray of ACM for
his help in codifying this \textit{Author's Guide}
and the \textbf{.cls} and \textbf{.tex} files that it describes.

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{report}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
\begin{comment}
%APPENDICES are optional
%\balancecolumns
\appendix
%Appendix A
\section{Headings in Appendices}
The rules about hierarchical headings discussed above for
the body of the article are different in the appendices.
In the \textbf{appendix} environment, the command
\textbf{section} is used to
indicate the start of each Appendix, with alphabetic order
designation (i.e. the first is A, the second B, etc.) and
a title (if you include one).  So, if you need
hierarchical structure
\textit{within} an Appendix, start with \textbf{subsection} as the
highest level. Here is an outline of the body of this
document in Appendix-appropriate form:
\subsection{Introduction}
\subsection{The Body of the Paper}
\subsubsection{Type Changes and  Special Characters}
\subsubsection{Math Equations}
\paragraph{Inline (In-text) Equations}
\paragraph{Display Equations}
\subsubsection{Citations}
\subsubsection{Tables}
\subsubsection{Figures}
\subsubsection{Theorem-like Constructs}
\subsubsection*{A Caveat for the \TeX\ Expert}
\subsection{Conclusions}
\subsection{Acknowledgments}
\subsection{Additional Authors}
This section is inserted by \LaTeX; you do not insert it.
You just add the names and information in the
\texttt{{\char'134}additionalauthors} command at the start
of the document.
\subsection{References}
Generated by bibtex from your ~.bib file.  Run latex,
then bibtex, then latex twice (to resolve references)
to create the ~.bbl file.  Insert that ~.bbl file into
the .tex source file and comment out
the command \texttt{{\char'134}thebibliography}.
% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
\section{More Help for the Hardy}
The sig-alternate.cls file itself is chock-full of succinct
and helpful comments.  If you consider yourself a moderately
experienced to expert user of \LaTeX, you may find reading
it useful but please remember not to change it.
\end{comment}
%\balancecolumns % GM June 2007
% That's all folks!
\end{document}
